welcome everybody
to the second to last lecture of 6006.
uh in this lecture we've mostly covered
all of the testable material that we're
going to
have on uh the final or
on quiz 3 right today really what we're
talking about is
putting into context all the material
that we've
learned over the course of the term
at a high level and talk about where we
can go from
here in terms of other theory classes
and other classes in the department
that are related to this material now
most things in the department are in
some way related to this material and so
that's why this is a foundational course
but we're going to try to talk about it
from a high level and
talk about how some future
things that you might be interested
relate okay so
we started out the term in lecture one
talking about 6006 and we had
four main goals that we had for our
course really three main goals uh
did anyone remember what those goals
were
there was uh so uh here was i you got to
the last one first
the first one was to solve hard
computational problems right to be able
to solve problems
okay so this is kind of like the the
let's uh make an algorithm part of
of the course right one solve
hard computational problems
i guess hard here maybe should be in
quotes
because we saw in the last lecture what
hard means in a technical sense
right hard could mean that there's no
efficient algorithm that we know how to
solve
a problem on that's getting a little bit
of ahead of ourselves
computational problems with algorithms
is really the key
part about this goal it's kind of the
same goal that you have in a class like
601 or 609 right you're trying to
convince
a computer that you solved a problem
okay on a finite set of it inputs
but really what this class is about is
two other things
which is more about communication to
people rather than computers
right your your algorithm might be
correct or efficient
but you need to be able to communicate
that to humans and that's what the other
two goals are right
so second one is uh
argue
[Music]
correctness basically that the thing
that i'm doing
to my inputs is always going to lead me
to a correct output
right no matter what input i give it any
valid input there could be a
infinite space of possible inputs and in
this class that that's the case because
we want our input size to grow
arbitrarily large we need to be able to
argue correctness that it's going to
return me the correct thing
no matter what my inputs are and in
order to do that that's essentially
that's that's 6042 right this
this whole class has basically been
applied 6042
right i've given you some
procedures and you have to prove things
about these procedures or
most of the time we proved it for you
and then you've used them as black boxes
right but that's
that's a lot of what this class is about
and the third one is efficiency right
argue
argue that it's good for lack of a
better thing this is efficiency
what does good mean well that was hard
to know at the beginning of our class
and so we set up this model of
computation a framework
through which we could determine
how good or bad our algorithms were by
saying by defining a model of
computation
saying what things we can do in constant
time and then just
building off of that right so this is
basically our model
you know plus some you know asymptotics
or something like that
ran out of space what it's about
yeah this is about scalability this is a
model of computation tells us how
how much time we can spend but it's
compared to our input size
right this is always about how does our
algorithm
perform relative to the rate that our
problem size grows
right and so that's what we mean by good
and in this class we don't
tend to talk about constant size
problems it's about
how algorithms can scale as you have
arbitrarily large inputs
that's why we need recursion and
induction to be able to prove things
about our algorithms because they're for
arbitrary end and that's why we need
uh you know this relative to input size
the growth factor of of our algorithm's
performance
relative to the input okay and then the
last thing
is kind of to me one of the most
important things
is communicating these things to another
human right
so communication
is key here right if you can always
write good code that's always right
good for you i can't do that all the
time
but that might mean that you can be very
a competent independent computer
programmer
right but you're going to be limited
in what you can do if you're uh
if you're only able to rely on yourself
right a lot about computer science
is working with others to solve
computational problems
and when you're working with others to
solve computational problems
you need to be able to communicate with
them and you need to be able to
communicate them
both what it is you're doing
and why it is you're doing it right that
it's
you're doing the correct thing and that
it's efficient right and so that's a big
part about what this course is
it's at the end of the day on your quiz
if you write down um you know python
script
for a correct algorithm but we don't
know what it's doing
but it's correct we're not going to give
you
full points on that because you're not
satisfying
the conditions of this class right it's
really about the communication here
okay so just to review since we've not
uh discussed uh how
the most recent lecture fits into
your problem sets we didn't have any
problem sets that covered
complexity so how does that fit in
well argue that this is that the ways
that we're solving our problems are good
what we proved in the last lecture was
that most problems cannot be solved good
right they can't be solved in polynomial
time
with respect to the size of your input
however
most of the problems that we think about
in a sense i can i can prove to you that
it's a yes solution i can show you
a a simple path in this graph that has a
certain
length or i can show you a subset that
sums to a certain value
in a particular problem i can give you a
certificate that i can prove to you
in a reasonable amount of time that yes
i can prove to you that this is the
answer to this thing is correct
and that's what we talked about in the
last lecture what
so not always
good
algorithms
to solve problems
but many
problems
we think about
can be either
checked in
polynomial time
this is the concept of having a
certificate that i could give you of
polynomial size
that could be checked in polynomial time
right in
in a sense that's a away check
checked in polynomial time this leads to
our class of decision problems
np or you know can be
uh solved
by brute force
in exponential time right most of the
things that we've talked about in this
class
fall into one of these two categories
right we can just brute force over the
combinatorial space of possible outputs
and check to see if they're correct
right or i can give you
a certificate basically saying uh
look i can solve actually anything
that's of this form can be checked in
this form because there's only a
polynomial number of things to check
or sorry an exponential possible number
of certificates of polynomial length to
check
um but basically this is saying that the
the problems that we think of
mostly fall into these two categories
and so there usually
are algorithms to solve the problems
that we care about
even if most random problems
in terms of bit strings that we gave in
analysis
in the last lecture actually proved that
most random problems are not solvable
right though in a sense the problems we
think about
are not random they kind of have this
structure that they can be checked
pretty quickly okay so that's kind of
what we mean
when we're talking about complexity for
the purposes of the final
you'll be able to see on your final exam
uh practice
problems that we're going to give you
most of what we
uh cover uh in terms of
material on the final that will be cove
that will be testing the lecture 19
material
will be in terms of these definitions
do you understand what the the decision
problem class
np is x biz do you know
how these relate to each other x is
definitely a superset of
np here right np nestles inside here
they could be equal probably not right
those are the types of things that we
would address knowing kind of a
directionality of a reduction
right if you have a a problem
a and a problem b
right and i know that this one
is difficult by some measure
right i already happen to know that it's
you know very hard right like np hard or
something like that
if i can if if this is a problem that
i'm interested in knowing the complexity
about
and i can prove that i can solve it
if i had a black box to solve b
any black box to solve b and i could
make this reduction in polynomial time
and if this is hard that means this
can't be
that means that if this is hard then i
better not be able to solve this in
polynomial time
right because then i would be able to
solve this in polynomial time so that's
basically
the type of argument usually in a true
false question we might have
on the final exam for you to kind of
understand the basic
high level definitions involved in what
was
talked about in lecture 19.
hardness right the very most difficult
problems of these classes
and completeness sorry uh anything
harder
than things in these classes where
completeness is the
ones that are in this set but at least
as hard as anything in those classes
okay so that's just to give you a brief
overview of the only material that
hasn't been tested
but might be tested on the final okay
so when we don't have a good algorithm
we can actually prove that it uh doesn't
might probably doesn't have a good
algorithm
and that's kind of a problem that you'll
be able to solve
in future classes if you continue along
this track
okay so what's the actual content
that we talked about and this is a very
high level overview of why we're taking
this class why you're taking this class
right but what is the content we
actually covered it kind of
i like to break it up into three units
and kind of in a sense two
subunits okay so quiz one material
and quiz two material
was about showing you some nice black
boxes
right basically if i'm going to have
inputs of non-constant size
it's going to be useful for me to be
able to find
things among those elements right so
that's really what
quiz 1 is all about right data
structures
for finding
things in
a non-constant
size uh
uh database
sure and when we were storing these
things we want to support maybe two
different types of queries
ones that were intrinsic to the items
what the items were
and ones based on what an extrinsic
order was placed on these items
right and that was a way in which we
broke down
how should i approach looking at this
problem i want to be able to support
queries
and maintain an extrinsic order on these
things i might want to sequence
right this is a sequence
extrinsic order
or i want to be able to look up
is this thing in my set right by by a
key
that we identify it with a unique key
right
so this is some intrinsic
queries and often order
right not all like a hash table doesn't
maintain any order on my keys
right but it does support intrinsic
queries is this thing in my set or not
but we did show you other set data
structures that do support a
intrinsic order that allows me to see
what the next larger and next previous
uh the the the next larger the next
smaller
item is in my set
right so here's a summary of those
data structures that we had i'm not
going to go into
how to use these things or how to choose
from among them
here that's what your uh quiz 1 review
lecture was all about right
but basically the idea here is if we
have a sequence
most of the time when you're programming
being able to push and pop at the end of
a list
is pretty good which is why python the
most fundamental data structure that you
have
is a list because it's a super useful
thing i just want to store a bunch of
things
have random access to uh
the say 10th element to my thing
but i'm not necessarily having to
dynamically update
the order of these things in
dynamically i don't necessarily have to
insert something in the middle of the
list
most of the time what i can do is put it
at the end of the list
and maybe swap it down into place if i
need to right
so that's why a list is super useful a
sequence adl tree
useful but not as ubiquitous as a linked
lid
i mean as a dynamic array sorry i said
linked list
i meant python list which is a dynamic
array
okay so the dynamic array tended to be
in in in your coding practice your most
common sequence data structure here
though
uh we can get pretty good for this
insert in the middle operation
uh with the sequence avl okay then for
on the set data structure side
i kind of categorize these things into a
couple different categories here in
terms of the operations we can support
on these things these are all intrinsic
operations finding things
inserting deleting things i think of the
first three
as being dictionary operations right i
want to just look
look up whether something's there
whereas the last two
are order preserving operations where
it matters what the order these things
are stored in
and so as you can see
from the uh you know asymptotic
complexity of the various operations
here
the hash table is actually super good if
you want a dictionary upper
if you just want to support dictionary
operations
but in the cases where you need to
maintain order dynamically
a set avl is the way to go right
but if you don't need it dynamic but you
still need those order operations
a sorted array is just good enough if
you don't need to change what they are
right so that's
that's a quick overview of quiz one
type data structures material but then
we used
most of these data structures to get
faster
sorting algorithms in different contexts
right
basically everything on this list
involved
making a data structure and exploiting
that data structure to get a better
running time except all except for merge
sort really
right the first two we we presented
in terms of a priority queue right
whether we used a sorted array or an
array
we represented it at the end of lecture
eight
[Music]
to get n squared running time we
generalized that down to
to n log n by using a heap that was a
nice
optimization but we also got uh
interesting data structures using an av
i mean
interesting sorting algorithms using an
avl tree because of the power of
maintaining a dynamic order
over time but then exploiting
a direct access array to be able to
sort in linear time for small
bounded bounded in terms of the input
polynomially bounded in terms of the
input
ranges of numbers right so we we
leverage that
count direct access array to get
counting sort
and then we kind of amplified that
effect
by sorting on a bunch of digits uh
multiple times to get
basically polynomial uh blow up in terms
of the numbers that we could sort in
linear time
okay so that's a an overview of the
content of quiz one
in quiz 2 we were kind of like
okay now you know how to find things
within a
set of of just a flat list of things
right you can put it in a data structure
but in a sense a graph is a special kind
of data structure
right that relates the different things
in your input
right so uh if you've got
um a bunch of vertices right there's a
relation now between those vertices
that are your edges and this is a super
useful framework
in talking about discrete systems
because you can think of a vertex as a
state of your system
and then connect these transitions as a
graph right that's
that's the reason why i mean graphs are
awesome right but they're awesome
because they can be used to model so
many different things within our world
right it's not just about you know road
networks
right it can also be about playing your
favorite
uh turn-based game right like tilt right
okay so uh we we talked about a lot of
different types of problems that you
could solve
various algorithms with a focus on a
bunch of different ways of solving
single source shortest paths and again
just like the sorting algorithms and
just like the data structures we
presented
multiple of them because we had this
trade-off of
generality of the graph that they apply
to
contrasted with their running time right
so
i guess in in particular the the the top
um uh line there is
in some sense the most restrictive we we
don't have any cycles in our graph
that's a very special type of graph and
we're able to get linear time
but then even if we do have cycles in
our graph we can do better
if we have a bound on the weights in our
in our thing whether they
be uh there's an easy conversion to a
linear time algorithm via
an unweighted process or whether these
things are non-negative so there can't
be negative weight cycles and we don't
have to deal with that
okay so that's quiz two material
and then quiz three material was kind of
applying this graph material
to a recursive framework what was our
recursive framework
everyone say it with me dynamic
programming and the framework was
sort bot right missing a letter but sort
bot
right you can actually think of
the quiz 3 material as
uh as really an application of the graph
material
right what what are we doing in sort bot
we're defining a set of sub problems
this is a set of vertices in a graph
what is the relationship doing it's
saying
what are the relation between the
sub-problems
right essentially defining the edges of
a graph
right and then this topological order
and the base cases
all of these things are just saying what
is the problem that i want to solve on
this graph
and how do i uh compute that
for things that don't have any outgoing
edges right
i need to start writing the board again
this is graphs
there was a sorting in here too
this is basically an application
okay graphs was basically a relationship
on these
non-constant things
so this was kind of like useful black
boxes
right that you can just bundle up and
stick in some inputs stick out some
outputs and and you're golden
right whereas quiz 3 was very different
the material in quiz 3 is very different
dynamic programming
while it was
in some sense related to this graph
material i'm constructing a graph
i have to construct that graph there's a
creative process
in trying to construct that graph i
don't give you a set of vertices usually
what i give you
are a set of like a sequence or
something like that
and you have to construct vertices
sub problems that will be able to be
related in a recursive way
so you can solve the problem this is a
very much
more difficult thing than these other
things i think
because there's a lot more creativity in
this right
in the same way that just applying
reducing to the graph algorithms
we have is fairly easy but actually
doing some graph transformations
to change the shape of the graph so that
you can apply these algorithms
that's a harder thing to do right these
are these the the difficulty with these
two sets of materials
is very similar right figuring out what
the graph should be
figuring out what the sub problem should
be and how they relate
is really the entire part of the the the
entire difficulty with
solving problems recursively right and
we've only given you a taste
of solving problems recursively
in future classes like 6046
which is the follow-on to this one in
the undergraduate curriculum
this is all about introduction to
algorithms the next one's about design
and analysis
of algorithms right it's quite a bit
more difficult because
we are we've mostly uh
left it to you to use the things that we
gave you
or make your own algorithms based on
this very
nice cookbook-like framework
that you can plug in a recursive
algorithm to now actually that cookbook
is super nice for
any way of looking at a a problem
recursively
but while uh
while in dynamic programming the
inductive hypothesis
of of combining your sub-problems is
almost trivial
right uh in other types of recursive
algorithms
that's not necessarily the case okay
especially when
instead of looking at all possible
choices
for example in a greedy algorithm where
you're just looking at one of the
choices
the locally best thing and recursing
forward
you're not doing all the work right
you're not locally brute forcing you're
locally picking
an optimal thing locally and hoping that
it'll lead you to good thing
that's a much harder algorithmic
paradigm
to uh to operate under and so that's
more like the material that you'll be
talking about in 6046
okay so uh that's
double06 a very quick
overview of the content of this class
and we really like the structure of of
how this
this class is laid out because it gives
you a fundamental idea of
the things people use to store
information on a computer
and a sense of how you solve problems
computationally
and how to argue that they're correct
and efficient right that's
really what this problems this this this
course is about
and if you feel like you
enjoy this kind of stuff that's where
you go to take
6046 right and 6046 was actually
the first algorithms class i ever took
here at mit
uh as a grad student actually i uh
i didn't this is this is hard for me
right
it was it's actually hard to look at
these problems
these types and think in a computational
way especially
having not taken this class 6006.
so hopefully you guys are all in a
better position uh than i was when i
took it
there's there's two ways i like to think
of the content in 6046
one is kind of just as an extension of
double06 right
it's the natural follow-on to the things
that we do in this class
right they still talk about data
structures
this isn't the core part of 046 but they
do touch
on data structures for more complicated
uh
that have more complicated analysis
involved in them it's really about
you know usually in o46 stating what the
algorithm is doing is not
so hard right basically
giving you the algorithm number one here
is not so difficult to state what's
happening in the algorithm
but the number two and number three here
arguing that that thing is correct and
arguing that thing is efficient
that's where the complexity comes in in
o46
the design the the analysis part is
quite a bit more complicated in o46
than in 006 right so they
they solve a problem called union find
and give a much we talked a little bit
about amortization this goes into a much
better
a much more formal way of proving
things uh uh run in
amortized time okay so this is basically
amortization
the uh what we call a potential analysis
it's basically making that algo that
that that that uh
that notion that we talked about when we
were talking about dynamic arrays of
you know we're not doing this expensive
thing too often
basically what we do is we keep track of
the cost of all of uh sequence of
operations
and prove that the average cost is small
right that's that's kind of what this
potential analysis is doing it's a
little bit more formal process for
making that argument
uh a little uh more formal right okay
so then on on the graph side right this
is kind of
an extension of quiz one type material
this is
what what is this union find data
structure it's basically
it's a set type thing right
where i i can make a set
of just a single element i can
take two sets merge them together
make them their union right and then
given an object i i say which set am i
part of
right essentially by electing a leader
within a set
and saying return me uh you know a
pointer to that one
right and so this can be useful in
dynamically maintaining say the
connected components in a
dynamically changing graph
supporting the query of am i in the same
component and as this other guy
right that could be a very useful thing
to know about a graph as it's changing
so that's
that's an application of this problem
and they get
near constant performance for a lot of
these these queries
it's not quite but you know pretty close
okay on the graph side they solve a
number of uh
very useful problems on graphs uh
minimum spanning tree so i'm i'm trying
to find
a tree connecting all of the vertices in
a connected component of my graph
and i'm trying to find in a weighted
graph i'm trying to find
the spanning tree that has minimum total
weight
right so this is that's a problem a
fundamental problem in
graph weighted graph algorithms
they've solved this via a greedy
algorithm okay
and network flows
uh and i guess cuts right so this is
what is this this is i'm given a
weighted graph
uh basically each of the um
the weights correspond to a capacity i
could push water through along this edge
right and it may be given a source
vertex and a sink vertex
right and i want to say i want to shove
water through the source vertex
along the edges with their various
capacities and
i'll get some amount of water on the
other end in the source
right so the question is what's the most
amount of water that i can push through
this well i could build
build that pipe network with the
different things and just do this
experimentally i just
stick a bunch of maybe i i'm a
mechanical engineer so that that maybe
makes sense to me but
you want to be able to just look at
those numbers and be able to tell me
how much water can i push through that's
what the kind of
max flow in the network is talking about
and we give you some polynomial time
algorithms in this class
basically incremental algorithms that
kind of like
dijkstra or kind of like bellman ford
will incrementally update uh
estimates to uh
of of a max flow and and improve them
over time
okay uh then
on the basically design paradigms
you've got more involved making your own
divide and conquer algorithms
you know dynamic programming algorithms
greedy algorithms basically
they go a lot more in depth in terms of
how to design these algorithms in these
paradigms
than we do in this class okay and then
the last thing
is we only touched on complexity
and in a sense 046 is only going to
touch on complexity it's a very big
field
right but it will give you the tools
to be able to prove that something is np
hard
whereas we just kind of say that oh
there's this thing called reduction
we didn't give you any uh problems in
which you actually had to reduce one
problem to another
and you'll do a lot more of that here so
reductions so
in a in a big sense
oh four six is really just a natural
extension
to the double o six material plus some
additional stuff which i'm gonna get to
in a second yeah question
randomization uh i'm going to
talk about that slightly in a in a
separate uh
i'll get to your question in just a
second i like to think of it
as a separate topic which i'll we'll go
into right now the separate topic i like
to think of it as
instead of being the natural extension
to the things in
in the double 06 units
what i'm going to do is kind of
relax either what it means to have a
correct algorithm
or relax what it means to uh
what my model of computation is okay
so double o six this is kind of
as an extension
of double o six
and this is kind of like 6046
as you know
change
my definition of what it means to be
correct or efficient
so
we've already kind of done this a little
bit in double o six
um i'm gonna
basically one of the things that we can
do which is what the question that
uh student asked a question about was
about randomized algorithms which is a
big
part of o46 actually randomized
uh analysis of algorithm of algorithms
that are not deterministic
right it's it's not guaranteed that
it'll give you the same output every
time or
not guaranteed that it will do the same
computations over the course of the
algorithm every time
but it exploits some randomization
and in double six this is we've mostly
not touched on this except in one area
where did we use randomization in
hashing
right right when we used hashing
what were we doing what what what did we
change the definition of correct
versus efficient we didn't really change
the definition what we did was
we said that it was okay that sometimes
our algorithm was slower than we
then then on in expectation right that's
what we
we meant there right we're relaxing the
idea of efficient
but we're still saying it's good because
most of the time it is good
right so this there's two types of
randomized algorithms
uh they have these weird names uh based
on
betting uh uh regions of the world shall
we say
there are uh
this is el oh las
ladies loss okay vegas
algorithms uh these are always correct
but probably efficient
in a sense that's what hashing is right
i'm always going to give you the right
thing right whether this thing is in my
set or not
but some of the time it's inefficient
right i have to look through
a chain of length of that's linear in
the size of the things that i'm storing
okay and this is in contrast to a
monte carlo
algorithm which is always efficient
for some definition of efficient but
only probably correct
and i mean i could define you a hash
table that has
monte carlo semantics instead right say
for example
i i say that i'm gonna it's to be
exactly the same as a hash table
except instead of storing all the things
that collide in a place
i just store the first two say
right well actually
that's actually going to be always
efficient i'm going to look through the
things and see if it's in there
and the chan the chains that i'm storing
there only have two things
it's going to be always efficient it's
always going to give me constant time
but some of the time it's going to be
the wrong thing because i'm not storing
everything in that chain
right so there's some probability that
that's not going to be correct
right and so that's that's a different
kind of if maybe i want my hash tables
to always be fast
but i can afford to be wrong some of the
time
i don't know in practice this is
actually sometimes a good trade-off
in real systems sometimes it's okay to
be wrong some of the times
if we get good performance okay
so but generally
can do better
uh if you allow
randomization and by better i mean
you know usually we can get faster
bounds on a lot of problems
if we allow randomization and things
aren't necessarily always correct
or always efficient okay so
this is a big area in 0 4 6
that requires a lot more analysis using
randomness and probability so if you're
uh
needs some uh primers on that we didn't
have
a lot of this in in double o6 but if you
go on to o46
that's going to be a really important
thing for you to brush up on
okay the next part on
double06 is kind of changing what our
definition of
correct or efficient means i mean we've
restricted ourselves in this class to a
class of problems
where we only talk about integers right
but there's tons of problems in this
world especially in scientific computing
where i want to be able to find out what
the
this real number is and i can't even
store a real
number on my computer so what the hell
jason
what are you talking about right i can't
do that on a computer
but what i can do is basically
compute things in a numerical sense
numerical
algorithms
and in o46 a lot of times we put this in
the context of continuous optimization
continuous uh being the opportune word
here not discrete systems you have a
continuum of possible
solutions real numbers essentially
how do we do this on a computer that's a
discrete system
basically what what what in o46 what you
can do and in other numerical methods
classes
what you can say is well i know that you
can't
return me a real number i got that or or
you can maybe
have a model of computation that allows
integers to represent
other kinds of real numbers like
radicals or rationals or something like
that and i can do manipulations on those
but really what these these algorithms
are usually about is
computing real numbers not completely
but to some bounded precision and i pay
for that precision right
the more bits of precision i want on my
number
i have to pay for them right so this is
basically
i think of these as an approximation
a approximation
of real number
to some
precision and
i pay
for precision
with time
so let's say you know i want to compute
the square root of a number
i could have an algorithm just like the
algorithms
or i guess division right long division
you all know the algorithm of long
division you you know you put
a quotient under here with these you
know an a b and you get the
c on top or whatever right that's an
algorithm that's a procedure
using essentially small numbers i'm only
talking about the digits 0 to
9 here when i'm doing that algorithm so
it's a procedure
that only uses small integers to compute
arbitrary precision of a division
right so that's an algorithm and i have
to pay time
to get more digits right so that's
that's an
uh uh an example of this kind of how
how we live in the world of real numbers
when all we have is a discrete system
okay and then the last kind of
category i'd like to talk about here is
is really
approximation algorithms
whereas this is kind of an approximation
algorithm i'm approximating my outputs
this is an approximation algorithm from
the standpoint of
well there's a lot of problems that i
can't solve efficiently they're np
hard they're they're in x or
you know even harder problems
but uh maybe i'm okay with not getting
the optimal solution so this is in the
domain of
optimization problems
so most of the dynamic programming
problems that we gave you are
optimization problems or the shortest
paths problems those are optimization
problems basically
the possible outputs are ranked in some
way right the
distance of a of a path that you return
or something like that
they're ranked in some way there's an
optimal one right the one with the
the smallest metric or something like
that right
well in an approximation algorithm what
i do is okay i get
that it's computationally difficult for
you to give me the longest pa
simple path in this graph or the
shortest possible route for my traveling
salesman
but maybe
that's okay i mean my engineering
spidey sense tells me that within 10 is
fine
right so maybe instead of giving me the
most
optimal thing can i give you an
algorithm that's guaranteed to be within
a certain distance from the optimal
thing
right usually we're looking for constant
factor approximations which are
have low constant or you know
maybe even have to do for worse if such
things don't exist
okay so that's approximation algorithms
you know
can we get close to an optim optimal
solution in polynomial time
okay and then the last
way we could change things in especially
future classes though sometimes they
talk about this
in o46 as well is we could change the
model of computation
right we could basically change
something about our computer
to be put in some other weird paradigm
of of
of solving problems with more power
essentially or
or you're in a situation where there's
less power okay so change in the model
of computation
okay
so what we've been talking to you in
terms of model of computation is our
word ramp
right word ram
that essentially says i can do it
arithmetic operations and i can look up
stuff in my memory in constant time
and but if i allocate a certain amount i
have to pay that amount and that kind of
thing so that's this
word ram model but in actuality
all of your computers you know it's a
it's a lot easier for me to figure uh to
find and read
memory that's on my cpu in a register
then it is for me to go out to the hard
disk ask this
well in my day it used to be this this
movable mechanical head that had to
go and scan over a bit on a on a cd-rom
drive
and you know actually read what that
thing was
right so we can add complexity to our
model to better
account for the costs of operations on
my machine
one of those models is called the cache
model
a cache model
it's basically a hierarchy of memory
right i have you know my registers on
board my cpu
i have maybe an l1 cache that's close to
my uh cpu then i have another set of
caches and another set of caches maybe
out to ram
and reading from a hard disk is a solid
state drive of some kind
that's the slowest thing to access and
i can put a cost associated with each of
those things and instead of having to
having all of our operations be you know
say said to be constant the constants
are actually different
and i have to pay for that difference
okay and so that's
you know extending our model to be a
little bit more realistic to our machine
you know another one is you know we have
computers right now that opera
operate in classical physics right that
exploit things in classical
physics but in actuality
our world allows for
even more complicated types of
operations
like quantum operations where you're
exploiting entanglement and
superposition of different atoms
to potentially get operations that i can
act on my data that are actually
provably stronger than the classical
models
in some sense right so this is the whole
huge reason why
uh there's a lot of work being done in
say
you know lots of uh industry research
facilities
in figuring out these models because
maybe if you can make a big enough
quantum computer you can break in
christian
and stuff in polynomial time and that's
something that maybe the nsa is
interested in and
i'm not going to go into that but you
know
i mean some people like you look at
artificial intelligence and things like
discussions around
artificial intelligence my brain
you know might be doing things that a
classical
computer cannot right it could be
using quantum superposition in some way
and our computers
that are in your phone and your laptop
and things like that aren't exploiting
those operations so how could we ever
get intelligence because
you know in some sense our brains are
more powerful right
and so a lot of what ai should be
looking into
is what is the actual model of
computation of our brains that can give
us the power to have sentience
right okay so that's that's kind of
quantum computing i don't know much
about it actually
uh and then there's things like maybe i
have
more than one cpu right
i i mean most computer all the computers
you have even the ones in your phone
probably have multiple cores
right in a sense you have lots of cpos
running in parallel
right so this is like pair uh there's
one
r in parallel
okay parallel computing basically says
you know
it's cheap for me to make another
computer potentially
right if i have two computers running on
the same problem
maybe i can get a two-fold speed up
on my on the this the time in which it
takes to
solve my problem now that's not
i mean suppose i had then 100 cpus
running on a machine
maybe i can get 100 fold speed up and
and actually in in real life
a hundred fold speed up makes a
difference
right it's am i waiting for this for 10
minutes
or am i waiting for this for a thousand
minutes right that's
that's like all day i don't want to do
that that's maybe it's on weeks i don't
even
remember right okay but parallel
computing right
if i can get a 100 fold speed up that
might be a huge win
but for some problems it's not possible
you know if i have k cpus
can i get a k factor speed up it's not
always possible to do
okay and so parallel computing is
another paradigm
in which uh there's a lot of interesting
theory going on
uh there's a lot of complications there
because
you know there are a couple different
models you could have a multi-core setup
where
you have a lot of computers that are
accessing the same bank of memory
and then you don't want them all to be
reading and writing from them
at different times because you don't
necessarily know what their state is and
you get
these collisions which are something
that you really have to think about in
this world
or you have situations where maybe i
have a bunch of
nano flies or something that are going
around
and they have very small computer brains
themselves
right but they can talk to each other
and pass information to each other
but they don't have access to one
central network repository of
information
that's what we call a distributed
parallel system
where all of the you know cpus that you
have can
interact with each other maybe locally
but don't have access to the same
uh memory system so they have to work
together
to gain to to learn information about
the system
okay so this is that's a a brief
overview of the different directions
this class 6006 and theory in general
could lead you
into a huge array of different uh
branches of theory
and different problems that you could
address with different types of
computers
okay so uh i know this is a very high
level lecture
and uh and maybe less applied than
some of you might like but i hope this
gives you a good understanding of
kind of the way the directions you can
go
after this class uh that i think are
really excited
in terms of uh how to solve problems
computationally
okay so with that uh i'd like to end
there