hi everyone welcome to the
uh 11th lecture of 6006
our first lecture on weighted shortest
paths
until uh now we've only been talking
about graphs that
uh where we measure distance in terms of
the number of edges
in a path right today we're going to
generalize that notion but i just want
to
go over what we've talked about in the
last two lectures uh
in the last two lectures we've talked
about two algorithms breadth first
search and depth first search
to solve a range of problems here's some
of the problems that we've
been solving single source shortest
paths
where distances are measured in number
of edges in a path
and we use bfs to solve this problem
starting from a single source usually a
vertex s
that we we call uh and and we solved
that in linear time
right and we solved that in
order v plus
e that's what we called linear time for
a graph
for the special case of single source
reachability
here we had to return a shortest path
distance for every vertex
and there was at most e things reachable
from a vertex
so this is uh
the bound we got but in the special case
for single source reachability
when our output only has to list the
vertices that are reachable from me
the the number of things reachable in a
uh basically a spanning tree of the
connected component of my source
can almost be of order e and so
for all the little singleton vertices in
my graph
i don't really care right so i can get
this in order e but that's kind of a
little optimization the next
thing we did was we talked about
connected components
and we didn't just reduce to using a
search algorithm
like a single source reachability
algorithm like bfs or dfs
we put a for loop around that to explore
the entire graph by basically saying if
i've
explored one connected component
then i can look at any other vertex i
haven't seen
and explore the next one right and so
that actually with some
a little analysis also got linear time
because i'm at most
traversing any component of my graph
once
that's kind of the the idea and then and
we can use that using
bfs or dfs really because we're just
trying to get
a thing that searches an entire
connected component
and then this topological sort we did at
the end of the last lecture
we used full dfs to give an ordering of
the vertices
in a dag i maybe i'll specify
clearly that this is only for a dag
right
where we uh have an ordering of the
vertices so all the edges go
forward in that order for example okay
and that we also did in linear time
all right in this lecture and in
actually the next four lectures
what we're going to do is
instead of measuring distance in terms
of the number of edges in a path
so previously distance
equaled number of edges
we're going to generalize that notion so
instead of counting
an edge we're going to count
an integer associated with that edge
it's going to be called a weight
all right so here's an example of a
weighted graph g and i've labeled in red
weights for each of these edges there's
a directed graph on eight vertices
and i've got a integer associated with
each edge you'll notice some of them
are positive some of them are negative
it's okay to be zero as well
it's just any integer edge weight here
so generally we're going to be along
with our graph g
we're going to be given a weight
function
that maps uh the edges of g
to we're gonna say integers
okay in this class anyway
uh in other contexts in mathematics you
might have this be real numbers but in
this class we're going to deal with
integers
so each edge if you have an edge
we're going to say this is the
edge weight the weight of this edge e
from e we we might sometimes if if this
edge e is u
v right we might sometimes say
the weight from u to v
since we have a simple graph that's
unambiguous
right all right so but this is just
talking about our notation so
in general for example the weight from
vertex
b to f in this graph is what can someone
tell me
minus 4 right it's right here and i'll
be consistent with my coloring
because i've got colored chalk today
-4 happiness all right so
why do we care about adding weights to
our graph
well this comes up a lot in many
applications for example
you know distances in a road network
right if i have a road from
here uh so so from mass ave
uh front of mit to central square
we might think of that as one road maybe
maybe you've got
uh each road is a connection between two
intersections
in my road network but an edge
it takes longer to go from say vassar
street
to amherst that takes a shorter amount
of time than it does to go from
memorial drive across the river to
beacon street
right so we might want to associate a
larger distance or a weight
associated with that edge right
latency in a in a in a network for
example
maybe strength of relationships in a
social network and you could imagine
that it's possible maybe you're
frenemies with someone
right like you you don't like them and
so maybe you have a negative weight
associated
with an edge in a social network i'm not
sure
maybe not but there are lots of
applications where you might want
weights on your edges
so that that comes to the next question
of how do i represent how do i give
the user or the algorithm these weights
in my graph right we had a represent
representation for a graph
right our common way to represent a
graph was
store a set data structure on the
vertices
mapping to the adjacencies
of each vertex which we stored in what
we called an adjacency list which really
could be any data structure
right uh commonly it's just a
an array of the adjacencies but you
could also have that be
a set data structure where you can
query in constant time uh what
if a particular adjacency exists in that
graph
so a common way there are two kind of
common ways
to store these weights one
is just with every adjacency i'm going
to store its weight
maybe just in a tuple some you know
with each
adjacency
also store
weight of the edge that it corresponds
to
right just in any way right uh a second
way
instead of trying to modify our graph
structure that we gave you before
let's just have a dictionary of all the
edges mapping to their weights
right and we already know how to do that
just so any set data structure
any separate
set data structure mapping
edges to their i guess
weights bad notation but you get the
idea
okay and
it doesn't really matter how we're doing
this the the assumption that we're going
to rely on here
is that we given an edge
right given this vertex pair i can query
what
the weight of that edge is in constant
time right
and so if i'm going to do that i can
either store it with a
maybe a hash table of hash tables right
a hash table
mapping the set of vertices to their
adjacencies and then each
adjacency list stores its adjacencies in
a hash table and that way
in constant time i can check what the
weight is there or here i'm just
i could even have just a single hash
table mapping the pair
the the edge the tuple
constant size uh to its weight
right so either way is fine uh we're
just going to assume that we can
query an edge in constant time the
weight of an edge in constant time
okay so this is a that graph
example it's a little busy here i'm
probably going to erase that in just a
second
but we're going to move on to what
giving these edges
weights implies for uh kind of these
problems that we've defined in terms of
unweighted graphs right
in particular we're going to be
concentrating on
single source shortest paths again at
least for the next three lectures we'll
generalize that even still uh in the
in the next lecture i mean in the fourth
uh
in three lectures from now
but what we had here was that the
distance before
in an unweighted graph was the number of
edges in the path
here we're going to generalize that
notion kind of
obviously two weighted paths
right and the weight
of a path i'm going to call it pi so
some weight of
path pi
right is just going to be the sum of the
weights in the edges in the path right
so
edge in the path i'm going to sum
their weights right so that's all this
the weight of a path means it's just i'm
going to sum
all the weights in a path so if i took a
look at the maybe there's a particular
path here the path from a to b
to f to g right is going to be
minus 5 minus 4 2
that's going to be minus 9 plus 2 is -7
right okay so just as an example
so uh then
then what is the shortest path then well
kind of obviously among
all paths between two vertices it's
going to be one with the
minimum weight right yeah question can i
use the same edge more than once
can i use the same edge more than once
right now you're asking about the
distinction
uh in an art class which we have between
paths and simple paths
right so here a weighted path doesn't
really care if we visit an edge more
than once
right so if an edge appears more than
once in
pi we have to count that more than once
in the edge
weight in the weight of the path okay
great question
um but what we're going to see later on
is shortest paths
cannot repeat an edge more than once
uh in in certain contexts
right so so we're going to get to the
the
problem there a little later in this
lecture and we're going to solve that
in tomorrow's lecture but if you have
we're getting a little ahead of
ourselves but when we have negative
weights in a graph
it's possible that things go wrong we're
going to get there in about five lines
okay great so uh
the the shortest path
and in this case i'm going to clarify
that this is the weighted shortest path
right
is a minimum
mom sure uh
is a minimum weight
path you know
from s to t
right nothing too interesting here
but there's actually some subtleties we
have to deal with here
right uh we're going to call
just like we did with uh uh breadth
first search when we talked about
shortest paths we're going to define
the uh uh an expression for what the
distance or the shortest path weight
is between two vertices and that's going
to i'm going to represent that by a
delta
right a delta from a vertex
s to t is going to be
let's i'm going to do the wrong thing
first
the minimum over the weight of all paths
for all paths pi
from s to
t okay
so there's a couple things that go wrong
here
first thing that goes wrong is the same
thing that went wrong
with breadth first search right anyone
remember what could go wrong with
breadth first search
for this delta definition maybe there's
no path
right right so if the in except
if no path
just by convention we're setting uh
delta s t to equal
infinity but there's one additional
problem with weighted shortest paths
and it's a little subtle it's possible
that a finite shortest uh finite length
shortest path doesn't exist
and what do i mean by that it means uh
i could keep going through edges in my
graph
and continually getting a shorter
path right so if i can if the the
shortest
the minimum weight of a path from s to t
actually goes through an infinite number
of edges
then this isn't really well defined
right so
i'm going to change this minimum here to
in in mathematics we
just to be specific we call it an
infiema
right so if in the case where there
where
the uh the weight of a shortest path can
approach
arbitrarily small right then we'll call
this thing
minus infinity okay so
when does that occur
when does that occur when could we
have our shortest path go through lots
and lots of vertices well
let's actually take a look at this
example here can someone tell me what
the shortest path
is from a
to actually any vertex in this graph
ah okay so well we could
look at this this path i have to be
let's just take a look at b
right i have a path going from a to b
that is minus five okay that's pretty
good that's pretty small
right and it seems that if i go
around this graph through another way it
might be bigger right so i go
seven plus three plus
eight that's 15 minus one that's 14
that's that's much bigger than my minus
five so
it seems like minus five should be good
right anyone have a problem with this
path
or the problem with this being the
shortest path
and what your colleague just informed me
was that there's something interesting
happening
here in this graph in particular
we have a cycle from b
to f to g to c
that has negative total weight right
back back to b
right this has minus four plus two
plus one minus one right so that total
cycle
has a cycle weight
of minus two right this is negative
weight cycle
so uh if i wanted to get to b
i could go there via this minus five
weight edge
but every time i circled around this
cycle
i incur -2 to my pathway
right so i just keep going around this
cycle
over and over and over and over and over
and over again
and i don't have any finite length
minimum weight path
right in in such cases we just say that
delta
is minus infinity right so uh the the
problem here
is that uh we could have negative weight
cycles
deserves a capital letter negative
weight
cycles
it's a problem
in particular if
there exists a
path from
s to some vertex v
that goes
through
a vertex
on a negative
weight cycle
then i can take that path to that vertex
circle around the negative weight cycle
and then proceed to v
and i can take that cycle as many times
as i want then
this delta sv we're going to set to
minus infinity okay and in such cases
in our shortest paths algorithm we don't
really care
about what the shortest path is right
we're not even going to deal with
parent pointers here right because there
is no
finite length shortest path so i'm
just going to kind of throw my hands in
the air and say you know what i can't
return you a shortest path
but i might want to return to you
a negative weight cycle right if you
told me that this thing has bad
weight right maybe i want you to tell me
what a path is that goes through a
negative weight cycle
to get back to s right so that's what
we're going to talk about next lecture
this lecture
we are not going to talk about that we
are going to talk about weighted
shortest paths though
that's what uh the remainder
of this uh this unit on graphs is really
about is weighted shortest paths
okay so in weighted shortest paths we
actually know
an algorithm already to solve a subset
of weighted shortest paths namely
bfs right now
you're like wait jason bfs doesn't solve
weighted shortest paths we didn't even
know about weighted
graphs then right how does that solve
weighted shortest paths well
there's a couple cases where we might be
able to reduce
to solving shortest paths using bfs
can anyone think of such a scenario
uh so let's say
i mean kind of what we did before was we
counted the number of edges
right so if we gave a weight of one
to every edge in my graph then
just that graph that weighted graph
corresponds to
an unweighted graph using the other
distance metric
right so in that case bfs just solves
our problem
and in fact we can generalize further
what if all of our weights were positive
but the same value
right if it was all positive and the
same value
then we could just to you know divide by
that value
right now we have a weighted an
unweighted
uh graph which we can run bfs and then
multiply shortest path distances by that
value
later on and in fact there's one further
generalization we could make
which is a little bit of a tricky graph
transformation problem
but we can also get this linear time
algorithm
for weighted single source shortest
paths
in contexts where
the weights aren't that large okay so
if i have positive edge weights
right if i have a positive edge weight
let's say
using using my weight color here
that's like weight of four right
that's that's kind of problematic
because i don't know how to simulate
that using an unweighted graph
or do i anyone have an idea of how i
could
simulate an edge of weight
four with an unweighted graph yeah
i have four edges of weight one yeah i
can just put four edges of weight one
in parallel here sorry in series
the opposite of parallel okay i can just
convert this
here into one two
three four edges
and if i do that for every edge in my
graph and we have positive edge weights
then that that transformation can hold
now that's not necessarily a good
transformation to make
y
yeah the weights might be very big
compared to the number of vertices and
edges in my graph
however if the sum of all weights in my
graph
is asymptotically less than
v plus e right we can get a linear time
algorithm again
by reducing to bfs okay so that's great
today uh but but in general that that
gives us a linear time algorithm in this
in these very special cases
and in general it's an open problem we
don't know
uh whether we can solve the single
source
single source shortest paths uh problem
in the weighted context
for general graphs in linear time we
don't know how to do it
right but what we do know are some
algorithms that do
pretty well and that's what we use all
the time
but in the sp one more special case
we're going to go over today
is when we have this really nice
structure
where we have a dag a directed acyclic
graph like we were talking about
in the last lecture we can actually for
any set of edge weights right remember
with bfs we kind of
we needed to restrict our edge weights
to be positive
and maybe bounded to get this good
running time uh
for any set of edge weights if our graph
structure is a dag
really has nothing to do with the
weights if the graph structure is a dag
then we can actually solve this single
short shortest paths problem in linear
time
which is pretty awesome right
now for general graphs
we're going to show you in the next
lecture
how to for any graph even with cycles
even with negative weight cycles
we're going to show you how to solve
this single source shortest paths
problem
in something like a quadratic running
time bound now this isn't the best known
but it's a really practical algorithm
and people use it all the time
okay and and it we're going to
uh show bellman ford in the context of
the dag algorithm we're going to
solve today okay so that's the very
general case in terms of restrictions on
our graph
but in reality most problems that
that come up in applications occur with
graphs
that have positive edge weights okay you
can think of a road network
you've got or non-negative ones anyway
right that you you're you're traveling
along
right uh and it's not ever useful to
kind of go back to where you came from
because you want to make progress to
where you're going
okay so in the context where you
don't have negative weights you don't
have this problem where you have
negative weight cycles
we can actually do a lot better by
exploiting that property
uh and we get a bound that's a little
bit that looks a little bit more like
n log n right like it's it's pretty
close to linear
you're losing a log factor on the number
of vertices
okay but it's pretty good this is called
dijkstra and we'll get to that in two
lectures
okay so that's kind of the roadmap of
what we're going to do for at least the
next three lectures
uh but before we go on to showing you
how to solve
single source shortest paths in a dag
using this algorithm called
that i'm calling dag relaxation here
uh i'm going to go back to a thing that
we talked about in
breadth first search where in breadth
first search when we solve single source
shortest paths
we output two things right we output
single source shortest paths these
deltas right for
the other definition of distance
you know the weights i mean not the
weights the uh the distances the
shortest distances
uh but we also return parent pointers
right we return parent pointers back
along paths to the source
along shortest paths right we called
this the shortest path tree so
i'm going to revisit this topic of
shortest paths tree
shortest path trees
shortest
path trees
okay and in particular it's kind of
going to be
annoying to talk about both of these
quantities
right distances and parent pointers
as we go through all three of these
algorithms right it's basically going to
be bookkeeping
to distances are actually sufficient for
us
to reconstruct parent pointers if we
need them later okay
so what i'm going to show for you prove
to you now is that if i give you
the shortest path distances
for the subset of the the graph
reachable from
s that doesn't go through negative
weight cycles
right if i'm giving you those distances
i can reconstruct
parent pointers along shortest paths in
linear time
for any graph i might give you if i give
you those shortest path distances
okay so that's what i'm going to try to
show to you now
uh so here's the
uh algorithm
for weighted uh there's the caveat here
i'm going to write down
for weighted shortest paths
only need
parent pointers for
v with
a finite
shortest path distance okay
only finite shortest path distance right
we don't care about the
infinite ones or the minus infinite ones
just the finite ones okay
so here's the algorithm i'm going to
initialize
all pv
to equal uh sorry
oh
getting out of myself i'm writing down
dag all right
uh init all
and knit my parent pointer data
structure right
to be empty
okay right first i'm not going to store
any parent pointers
but at the beginning i'm going to set
the parent pointer
of the source to be none
right so that's what we kind of did in
breadth first search as well
right now
what i've given you is i'm trying to
show that given all the shortest path
distances i can
construct these parent pointers
correctly so what i'm going to do is
for each
vertex u
in my graph where
my delta s of u
is finite
what am i going to do i'm going to say
well
let's take a look at all my outgoing
neighbors
okay this is kind of what we do in every
graph algorithm
for each
v in the adjacency the outgoing
adjacencies of
u
if there's no parent pointer assigned to
this v
right there's the potential that i
you i you this this u this vertex u
is the parent of v it's possible right
it's an in it's some incoming edge
to v okay when will it be an
incoming edge to v if i haven't said
if uh v
not in p right i haven't assigned it a
parent pointer
and so this means
it could be my parent
when is it my parent along the shortest
path
sure sum the distance along the edge
yeah so we have some edge from u to v
it has some weight right if i
already know the shortest path distance
to u and i know the shortest path
distance to v
right if
the shortest path distance from s to u
let's let's draw a picture here we've
got s we've got some path here
to u and we've got an edge
from u to v okay
if this shortest path distance
plus this edge weight is equal to the
shortest path distance
from s to v
then it better i mean there may be more
than one shortest path but this is
certainly a shortest path
so we can assign a parent pointer back
to you okay right so let's write that
condition down
if the shortest path distance from s to
v
equals the shortest path distance from s
to u
and then traversing the edge from u to v
then then exists
shortest path
that uses
edge uv right in particularly
in particular this one right
so set the parent
of you a v
to you okay so this is the algorithm
i'm not going to prove to you that this
is correct
but it kind of intuitively makes sense
right if i have these
shortest path distances right you can
prove by induction that not only does
this
parent pointer point to the right place
along some shortest path here
right but it also does so in linear time
because i'm looping over all the
vertices
and looping over its outgoing
adjacencies once same analysis as we had
for
both bfs and dfs essentially
right and then since we can do this
since we can con
compute parent pointers from these
distances
we're going to kind of ignore computing
these parent pointers from now on
right we're just going to concentrate on
computing the distances because
you know we're gonna have to take linear
time anyway right
at least and all these other things take
more time
so we can compute the distances in more
time and then
compute the parents after okay
so that's what we're going to do
okay so now with all that build up
let's show an algorithm right how do we
compute shortest single source shortest
paths in a dag
in linear time okay
well a debt i mean this is actually a
super useful convenient thing
in algorithms in general dags are just
nice things right they're kind of
ordered in a way right there's this
topological sore order
that we were talking about before this
is going to play a key role
right there's a really nice structure to
dags not having cycles
not having to deal with this negative
weight cycle problem
right you can only kind of go in one
direction
along this graph right
it's very nice structure to exploit and
so we're going to exploit it
and here's the idea dag relaxation
what it's going to do is it's going to
start out with some
estimates of what these distances should
be right
okay so maintain
maintain distance
estimates
and now i'm going to try to be careful
here about how i draw my
d's
okay this is a d
this is a delta okay this is
shortest paths this is a distance
estimate
okay so that's what i'm going to be
using for the the rest of this time
so we're going to initialize maintain
these
uh estimates of distance d which are
gonna start at
uh initially
infinite right okay i don't know what
they are
right i don't know what the shortest
paths are but they better be less than
infinite
or else i don't care right so i'm going
to that's the kind of worst case
scenario
right it can't be worse than this for
every vertex
and we're going to maintain the property
that
estimates
upper bound
that should probably be two words upper
bound
uh delta sv
uh we're going to maintain that the
upward bound this thing
and gradually lower
until they are equal
okay so this is the idea we start from
an overestimate an upper bound on the
distance estimate and then
we're repeatedly going to lower that
value
as we gain more information about the
graph
maintaining that we're always upper
bounding the distance
and we're going to keep doing it keep
doing it keep doing it until
as we will try to prove to you these
estimates
reach actually reach down all the way to
our shortest path distances
okay so when do we lower these things
when do we lower these things we're
going to lower
these distance estimates whenever the
distance at estimates violate what we're
going to call
the triangle inequality okay what is the
triangle inequality
triangle inequality is actually a pretty
intuitive notion
okay it's basically saying if i have
three points
that's thus triangle right uh
maybe bigger so i can write a letter in
them
okay it's basically saying that if i
have a vertex u
a vertex v vertex x for example
right the shortest path distance
right the shortest path distance delta
of uv
that's the shortest path distance from u
to v
it can't be bigger than a shortest path
from u to v that also goes through x
right right i'm i'm of of my paths i'm
now restricting the
paths that i have to the ones that go
through x
right the shortest path distance from u
to v can't be bigger than
restricting paths that go through x and
taking that shortest distance
right getting the shortest path distance
from here and adding it to the shortest
path distance here
right delta u x
delta x v
right
i mean that that's just a statement of i
i'm restricting to a subset of the paths
i can't
increase my i can't decrease my minimum
distance right
so this is the statement of the triangle
inequality right that the
shortest path distance from u to v
is can't be uh bigger
than the shortest path distance from u
to x
plus the shortest path distance from x
to v
for any x in my graph that's not u and v
okay so that's the triangle inequality
pretty intuitive notion right okay why
is this useful
okay well if i find
if i find an edge in my graph
if there's an edge u v
in my graph
such that
this condition is violated for the
estimates that i have
right it obviously can't be violated on
my shortest path distances but if it
violates it on the estimates
u v is bigger
than u x uh sorry u
how am i going to do this i want this to
be s
i'm calculating shortest path distances
from
s and shortest test distances from
s to some incoming vertex u
plus the edge weight from u
to v okay all right so
what is this doing i have some edge
u v in my graph okay basically what i've
said is that
i have some distance estimate to you
but going through making a path to v
by going through u and then the edge
from u to v
is better than my current estimate
my shortest path estimate to v
that's bad right that's violating the
triangle inequality these cannot be the
right weights right these cannot be the
right
distances so how we're going to do that
is
lower this is what we said repeatedly
lower
these distance estimates i'm going to
lower this guy down to equal this thing
in a sense this constraint was violated
but now we're relaxing that constraint
so that this is no longer violated
right so that's i'm
relaxes a little weird word here we're
using it for historical reasons
but that's what we mean by when we say
relax this thing
is a violated constraint it's got some
pressure to be
resolved right and so what we're doing
is to resolve it we're just setting
this guy equal to this so it at least
resolves locally that constraint now it
may
violate the triangle inequality
otherwise other places
now that we've done this change but at
least this constraint
is now relaxed and satisfied okay so uh
relax
edge by
lowering
d of sv
to this thing okay that's what we're
going to mean by relaxing an edge
okay and relaxing an edge
is what i'll call safe it's safe to do
okay what do i mean by relaxation is
safe it means that
as i am computing these shortest path
distances
right i'm going to maintain this
property that
each one of these estimates sorry
these estimates here has the property
that it's either
infinite or it is the weight
of some path to v okay
so that's that's the thing that
relaxation is safe
so each
uh distance estimate sv
is weight
of some path
from s to v
or infinite okay
and this is a pretty easy thing to prove
right if i had the invariant that
these were all weights of shortest paths
let's try to relax an edge
right and we need to show that this
property is maintained
relax edge uv okay
now if i relax edge uv what do i do
i set this thing
or uh sorry i set this thing my shortest
path
distance to v to be this thing plus this
thing
right this is an a weight of an edge
from u to v
now by my assumption that we're
maintaining
that this is a the weight of some path
in my graph
right if this thing is bigger
i'm setting it to the weight of some
path in my graph to u
plus an edge from u to v and so this
checks out
so
assign
d of s to v
to weight
of some path
okay i i'm not going to write down all
the argument that i just said here
but basically since this distance
estimate
was by supposition before the weight of
some path to v
to to u right then this is again
the weight of some path to v okay great
so now we're ready to
actually go through this algorithm
so dag relaxation
from over there
initializes
all of our distance estimates to equal
infinity
just like we did in bfs
then set
my distance estimate to myself to be
zero
right now it's possible that this might
be
minus infinity or negative at some point
but right now i'm just setting it to
zero okay
and either way zero is going to upper
bound the distance to s
right so in particular
at initialization
anything not reachable from s
is set correctly and s
itself is set as an upper bound to the
shortest path distance okay
now we're going to process
each vertex
you in a
topological
sort order
so remember our input to dag relaxation
is a deck
so this thing has a topological sort
order we're going to process these
vertices in that order
okay you can imagine we're starting at
the top
and all my vertices are all my edges are
pointed away from me
and i'm just processing each vertex down
this topological
sort line okay and then for each of
these vertices
what am i going to do i'm going to look
at all the outgoing
neighbors and if the triangle inequality
is violated
i'm going to relax that edge it's the
algorithm is as simple as that
for each
outgoing neighbor
of v sorry of u
i always get u and v mixed up here okay
if
my shortest path estimate to v
violates the triangle inequality
for an edge
for an incoming edge then i'm going to
set
relax
uv ie
set d
s b equal to d
s u plus w
u v okay so that's the algorithm
so if i were to take a look at this uh
example graph over here maybe
a is my start vertex i initialize it to
uh this is not a dag thank you
let's make it a dag
i claim to now this is a deck
okay in particular a topological sort
order is
when there's a path through all the
vertices then there's a unique
topological sort order
a b e f g h
d c this is a topological order you can
check all the vertices the edges
so i'm going to start with a uh
by setting
the uh well actually let's use e
let's do shortest paths from e why not
okay
shortest paths for me
vertex a actually comes before e in the
topological order
right so it has no i mean it's shortest
path distance when i initialize
i'm going to initialize this to zero and
initialize this to infinite
infinite infinite infinite
all these things to infinite these are
my estimates these are not quite the
shortest paths yet
distances but when i get here
clearly i can't be
distance to me being infinite can never
violate the triangle inequality with
something infinite or
finite doesn't matter right so
i don't do anything to a anything before
my source vertex in the topological
order
can't be visited right because it's b4
in the topological order that's that's
the kind of the point there's no path
from my source vertex to anything before
it in the topological order
okay so
same with b b is before it in the
topological order
okay now i'm at e
and it's possible we are violating
triangle inequality
in particular here right i think
the shortest path distance to f is
infinite
but actually if i go to e
through this edge with
a weight 3 i know that this is violating
triangle inequality
so actually this thing is wrong
and i can set it equal to 3.
okay now that might not be the shortest
path distance
but right now it's a better estimate
right so we've said it
okay now i'm moving on i'm done with
this guy
i move to the next vertex in my
topological order and again i relax
edges out of f okay so here
looking at eight three plus eight is
better than infinite
so we'll say that that's eleven
and three plus two is better than
infinite so that's
five okay now i keep going in the
topological order g is the next
five plus one is 6. okay so we found a
better estimate here
right so this 11 is not as good
6 is better so we replace it
here we haven't visited before it's
still infinite so
5 plus minus two is three
okay this is the next in the topological
order three
plus nine is bigger than six so that's
not a shorter path
three plus four is certainly smaller
than infinite so
set that equal to seven then seven plus
five
is also bigger than six and actually if
you can
you can confirm that these are all the
shortest path distances
from e okay so this
algorithm seems to work does it actually
work
let's take a look the claim to you
[Applause]
is that at the end of relaxation this
algorithm
we've set
claim
at end
all the estimates
equal shortest path distances
okay the basic idea here is that
if i take uh a
the cave vertex in the topological order
assuming that these distances are all
equal
for the ones before me in the
topological order i can prove by
induction
right we can consider a shortest path
from s to v
right the kth vertex and look at the
vertex preceding me along the shortest
path right that that
vertex better be uh
before me in the topological order or
we're not a dag
right and we've already set it short as
path distance to be equal
to the correct thing by induction
so then when we processed u right
s to u to v
when we processed u in dag
relaxation here processed the vertex and
looked at all its outgoing adjacencies
we would have relaxed this edge
to be no greater than that shortest path
distance
so this is correct you can also think of
it as
the dag relaxation algorithm for
each vertex looks all at its incoming
neighbors
assuming that their shortest path
distances are computed correctly already
right any shortest path distance to me
needs to be composed of a shortest path
distance to one of my incoming neighbors
through an edge to me
so i can just check all of them that's
what dag relaxation kind of does
and again we're looping over every
vertex and looking at its adjacencies
doing constant work
this again takes linear time okay so
that's
shortest paths in a dag
next time we'll look at for general
graphs
how we can use kind of the same
technique
in an algorithm we call bellman ford
okay that's it for today