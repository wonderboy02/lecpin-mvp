all right let's get started
welcome back to double06 today we are
doing some of the coolest data
structures we will see in this class
maybe some of the coolest data
structures ever binary trees
uh you've certainly seen trees in many
forms
uh in the past including in this class
we've talked to use trees as a lower
bound tool
for uh in the decision tree model
but this lecture and the next lecture
we're going to build
one data structure that is almost
superior to all data
structures we have seen and can do
almost anything
really fast first recall all the data
structures we've seen so far arrays
linked lists
dynamic arrays sorted arrays hash tables
and the two sets of operations we're
interested in supporting
the two interfaces one was sequences
where we're maintaining items in a
specified order we want to be able to
insert
an item right after another item or
delete an item in the middle of the list
and always be able to access the ith
item we haven't seen
any good data structures for that
problem we we're really good at
inserting and deleting
at the beginning or the end of the
sequence but we haven't seen anything
that's efficient at ins
inserting in the middle of the list or
deleting in the middle of the list
linked list
you can't even get to the middle in less
than linear time
uh array you can get to the middle but
if you make any changes you have to do
this shift which is very expensive
so today or sorry next lecture for the
first time we will see
all of those operations efficient
i'll mention our goal where efficient
means
logarithmic so we're not quite as good
as linked lists and dynamic arrays at
inserting and
deleting at the ends those there that we
achieve constant or constant amortized
time
but up to this log factor we're going to
get the best of all worlds where we can
solve
all the things all the operations that
don't
build or iterate through the entire
structure that of course takes linear
time
but we can do all the others in
logarithmic time for sets
sets were maintained maintaining a bunch
of items which have
intrinsic keys and we want to
search by key so hash tables are great
if you're only doing exact searches if
you want to find a key
and get yes or no is it in there and if
it's in there give me the item
that's what python dictionaries do and
they're
great at inserting and deleting but
they're really bad
at find previous and find next this is a
the unsuccessful case if i search for a
key and it's not in my structure
i would like to know more than just the
answer no i'd like to know what the
previous and next items that are
actually in the structure
so what are my nearest matches when i
search by key that's a natural query
and the only data structure we have
that's good at it is a sorted array
because binary search gives this to us
if we search for a key by binary search
and we don't find it
the position that we end up at is right
between the previous and next one
but of course sorted arrays are terrible
for dynamic
operations we don't know how to maintain
we can't maintain a sorted array without
any gaps
when we're doing insertions and
deletions in some sense today
and next class binary trees let us
represent
a sorted order or in general an order of
items
dynamically and still allow us to do
very fast things like get out of i and
find previous of the key
so that's our goal we're not going to
quite get to this goal today
we're going to get an incomparable thing
called the height of the tree and then
on thursday we'll be able to finish and
achieve this goal today is just
in service to that goal
so what is a binary tree
let me draw an example
and then define it more precisely
mathematicians will call this a rooted
binary tree
because in case you've seen that in o42
say
here is a picture
so this is an example of a binary tree
it has a bunch of nodes which we're
drawing in circles it has
items in the nodes which were i'm
writing as letters here
so this is item a item b item c and it
has these
links between them this is like linked
lists
but in general a node
x is going to have a parent pointer
a left child
left pointer and a right child
right pointer and it also has
an item inside of it so i'm going to
talk about node.left
is a pointer to the left
the node down here node.right
node.parent node.item
gives me so if i
look at the node a its item is
a so let me draw for you
some examples
okay the parent of a is nothing so we
call a
the root node there's going to be a
unique node that has no parent
it's uh sad to have no parents but there
you go
then we have node b which whose parent
is a
node c is parent its apparent is a node
d its parent is b
node e its parent is b and node f its
parent is d
alphabetical order here happens to be
ordered by parent
then we have left pointers i'll just do
a few of them so left pointer of
a is b right pointer of a
sorry b the node uh these should all be
notes
i'm circling for nodes and just writing
the letter for the item
make it clear that those are different
things uh the right pointer for a
is c left pointer for b is d
right pointer for b is e and so on
okay so in other words each of these
lines is a bi-directional pointer
uh in this direction it's the parent
direction in this direction it's left in
this case
because it's bidirectional we don't draw
the arrows we just draw
undirected lines okay
this is in general what a binary tree
looks like
a key invariant is that if you take a
node
and say go to its left pointer left
child and then go to that node's parent
this should be the same as node right so
that's just saying these
are in parent is always the inverse of a
left or right operation
this is also true for write
okay and that's a binary tree now the
intuition of what's going on here
is you could you could say it's we're
inspired by
a linked list linked list had a very
similar structure
maybe an item or there's a node it had
an item in it
and it had a next pointer and it had a
previous pointer
so in some sense what we're if it's
doubly linked we had a previous pointer
it was singly linked we only had a next
pointer
and if you think about the limits of
linked lists especially singly linked
lists
if you just have one pointer per node
you can only build a list
and so the result is uh
you know this this node is going to have
depth linear depth means how many
pointers do i have to follow to get here
from the root of the structure which for
linked lists was the head
it was doubly linked okay i can have a
head and a tail and i can put
bi-directions
on here but then still the middle item
has depth linear so there's no way to
get there
in less than linear time with binary
trees because we use
two types of next pointers left and
right
we can build a tree and we know trees in
general have logarithmic
can have logarithmic height
and so it's possible in a tree to get to
any node starting from the root in only
log n traversals so that's the intuition
of what's going on
now today
we're going to talk about the height of
a tree
so let me define
i'm going to need a couple definitions
here
subtree and height
of a node uh
so a tree decomposes into sub trees
so for example the subtree rooted at b
or the subtree of b
is this portion of the tree
so it's that node and all of the
descendants of this node so because we
have parents and children
we can generalize in the familial tree
sense
we can talk about ancestors of a node so
the ancestors of f
are its parent its grandparents its
great grandparents and so on
together all of these are called
ancestors
it's a it doesn't quite correspond to
familiar trees because familial trees
you have
two parents here you only have a unique
parent
or the poor root has no parent
we also talk about it's like mixed
metaphors
leaves of the tree
these are
people with no children parents will
complain about this
but many like many of us in this room we
have no children yet so we were called
leaves
you can tell your parents hey i'm just a
leaf you know blowing in the wind
so uh you know like this it's so many
mixed metaphors but we
always draw trees downwards like the
root structure of a tree
yet we call the ends of the roots leaves
which is upside down
anyway that's trees for you lots of
entertaining analogies okay but
ancestors are useful descendants are
also useful
so the descendants of b are all of its
children and all of its grandchildren
and all the way down
but just within the subtree so subtree
of x
consists of x and its descendants
and we think of x being the root
of that subtree so we're kind of
forgetting about everything outside of
the sub tree
when we talk about sub tree of x let's
talk about the
depth of a node
depth of the node is
i guess the number of its ancestors
right um but way i usually think of it
is
the number of number of edges
and in the path from
x up to the root
so every node has a unique path that
goes upwards
until it can't go up anymore so the
depth of e
is two because there are two edges uh
one two in the path from the root a to e
so maybe i'll write some depths uh depth
of e is two
depth of these guys is one depth of the
root is zero
two three so those are
depth i'm going to
clean this up a little bit
so we can focus on the image all right
height so depth is measuring
downwards because we you know if you
imagine depth within water
this is uh the surface of the water and
then we measure how deep you are from
the surface
height is in the reverse direction we're
going to measure from the leaf level
up because leaves are the bottom of the
tree so height
of a node is going to be
the number of edges
in the longest downward path
okay which is the same thing as the
maximum depth of a node
in x's subtree
let's do height in red
so uh how long is the longest path from
f to a leaf well f is a leaf so all
leaves have
depth zero sorry height zero
get it backwards um
d here it's so there are two
ways to go down this doesn't go to a
leaf uh this one goes to a leaf
and its height is zero so this height is
one there's one edge to a leaf here b
has two leaves it can get to we take the
longest one so that's length two
a similarly has height three
okay so height we measure upward depth
we measure
downward well one thing we care about uh
is just the height
of the overall tree uh which
is the height of the root
and i'm going to call that h because
we're going to use it a lot
and what we're going to achieve today is
all of these running times instead of
being log n
they're going to be order h
so today our goal is to get all the
operations we care about
in order h type
and then next lecture we're going to
guarantee that h is always log n
and then we'll get log n time so we need
to do a bunch of work to achieve log n
today we'll do the work that's all the
tree manipulation
and as long as your tree is nice and
shallow it doesn't have high height
if it has logarithmic height everything
will be log n of course there are trees
that are really bad
right we can have a tree
a tree like this which is basically a
linked list
where we only use right pointers and all
the left pointers are none
so there are height there are trees that
are very high
have high height um we want to avoid
these but we won't worry about that till
next lecture question
what is the height of node c height of
node c is zero
because the length of the longest path
the number of edges in the longest
downward path is zero yeah we're
counting edges not vertices
uh yeah so the height of the tree is of
course just the depth
the maximum depth i think that's right
so the height here is
three and the maximum depth is this
terribly drawn three
so these happen to correspond in the
maximum case
but we use height to always mean maximum
and so that's why
we talk about the height of the tree
depth of the tree is not defined
just depths of notes okay
um how do we use these trees to
represent
either a sequence or a set uh
i claim that there is a natural order
in trees called the traversal order
of nodes or items
and the tree so i'm going to define a
particular order
uh say in this example
let's do the example first the
traversal order
is going to be f
d b
e a
c i feel like i'm in music class this is
my guitar or something but it's not i
hope um
if it is a coincidence so
what is this order what i'd like to do
is um
recursively define an order where the
root of the tree is somewhere in the
middle
and everything in the left subtree is
left
earlier in the order than the root and
everything in the right subtree is later
so you can see here c comes after a and
then all the other nodes come before
a and recursively if i look at a node b
this node b which appears over here e is
to the right of it
but it's this is all to the left of a so
e
is between b and a would be on the left
and then f and d are to the left of that
and again f comes before d
because f is in the left subtree of d
okay so we say
for every node
the nodes
in x dot left are before x
and the nodes in x dot right are come
after x
and this uniquely defines an order
called a traversal order
it's also called the in-order traversal
order it's called in order because it's
in the traversal order so it's very
circular but
you may have seen inorder traversal this
is the same thing
there's a very simple algorithm for
computing this
if i want to iterate
uh let's call this yeah if i want to
iterate
all the nodes within a subtree x rooted
by x
i just iterate on all of the
nodes in the left subtree then i output
x itself
then i iterate on all the nodes in the
right subtree
okay you may have seen that algorithm
before this is just another way to
codify the same thing
the result is all the nodes within a
subtree appear continuously with no
interruptions
and then the parent parent's going to
come before after depending on whether
it's the left or right child
okay so and now it's just a matter of
connecting the dots because we're
representing an order
and for sequence that is going to be the
sequence order if we want to store n
items x0 through x1
we're going to build some kind of tree
we're going to put x0 here
x1 here x2 here x3 here x4 here x5
here you can see i'm very used to
dealing with traversal orders it takes a
little while
uh you could also see it here we're
going to put x1 on this node x2
sorry x0 here x1 here x2 here and so on
that's the same order that i gave
okay that's for sequences for sets that
order is just going to be the sorted
order
and we're going to be effectively
representing the sorted order of keys
say increasing but before we get to that
let's talk about different operations we
can do
just playing around with traversal order
and then we're going to use these to
build the sequence and set operations
that we care about
so first operation i'll call
subtree first seems appropriate that
it's called first
it's the first one so given a node
which i'll call node uh this defines
a subtree
which usually we draw subtrees as
triangles hanging off of the node
so here i would write x
and then there's some subtree of all the
descendants of x
so with subtree first i would like to
say among
all the nodes in this subtree
which comes first in traversal order
so just restricting to
that subtree so tree of that
so where is it in this tree
uh note is actually part of many sub
trees good question uh
f f is in its own in the sub tree of f
uh
f is also in the subtree of d f is in
the sub tree of b like i drew
f is in the subtree of a it's in the
subtree of exactly its ancestors
but in this operation when we define
node
our node only defines one sub-tree it is
the root of only one sub-tree
and that's the sub-tree we're talking
about and then i want to know among all
those nodes which includes node itself
and other things uh which one comes
first
in this traversal order this is like
practice with traversal orders
so where should i look for this node
yeah the leftmost leaf
in the picture it's here but pictures
can be deceiving
we just want to go left
as much as possible when i say go left i
mean this iteration node equals
node.left you just look at our
definition
all the nodes on the left come before x
and all the nodes in the right so
it's got to be in the left subtree if
there is one uh
of course we can't do this forever so
say until we would fall off the tree
which means uh node is none
okay but we stopped uh before that would
happen
so this is like uh the directions like
oh you keep driving until you see the
store
and it's the block right before that
it's like well that's not very helpful
so uh you keep iterating node equals no
dot left until node becomes
none and then you undo one step okay you
all know how to program that it's not
hard
um so that last non-none
node which might actually be the root it
might be node
maybe it has no left children but in
that case i claim node is the very first
in its in its subtree traversal order
because
if there are no nodes in the left that
come before x then x is actually first
okay and that so that's it uh return
node
so i'm modifying node in place here and
the very last one before i hit none
that's the minimum
that's the first item in the traversal
order similarly you can define subtree
last
okay let's do a more interesting one
successor
node so in this case i want to know what
is
the next
after node in the
overall tree's traversal order okay here
i was restricting to
uh a single sub tree now i'm thinking
about the entire tree in the entire
traversal order
and given a node i want to know which
one comes next
call this the successor i feel like i
should
make some kind of royal family joke now
but
i don't know how um so
every node has a unique successor let's
do let's do some examples
so we can start with f the successor of
f if we just index into this
list the successor is d okay
successor of d is b successor b is ease
okay it's very easy to read successors
off
when i have the traversal order written
down but let's think about how to do it
in the tree
okay uh
let's see there are going to be two
cases
if i look at the successor of a it has a
right child
and in this case the right child of a is
the successor but that's not always the
case
i don't have a good example but if i had
another node here let's call it
g uh the successor of a
is actually g right because
all of these items come after a in the
order
but which one comes first the leftmost
leaf
okay that's the problem we just solved
so if a has a right child
what we want is the leftmost leaf the
first
thing in that subtree
the right subtree right child sub tree
so this is case one
if uh node.right
so if we have a right child then
what we want is
subtree first
of the right child
great we can reduce to this other
operation
but what if the node doesn't have a
right child
so for example it could be a leaf say
we're taking
the successor of i mean it doesn't have
to be a leaf could be f which has no
children it could be d which has one
child but no right child
so what's the successor of f well it's d
which in this case is the parent but
it's not always for example if we do
successor of e
its parent is actually earlier in the
order because e was a right child
here f was a left child and so its
parent
was after
successor of d happens to be b because
uh it's per it was the left child of its
parent
okay so that seems like the easy case if
we're the left child of our parent
then our successor is our parent okay
basing on this small example but we can
argue it generally in a moment
what's the successor of e uh well it's
not b because that comes earlier in fact
all the things in this in b sub tree
come earlier or equal to
e um so we have to keep going up
and then it turns out the successor of e
is a because this subtree
was the left child of a because b was a
left child with a
so the general strategy is walk up the
tree
until we are we we go
up a traversal whose reverse direction
would be left
okay so um walk
up the tree when i say walk up i mean
node equals node.parent
iteration
until
we go up a left
branch
so this would mean that node before we
do the change
node equals node.parent node.parent.left
okay so we can check that and then after
we do that traversal that parent
is exactly the node we're looking for
okay why is this true in general let me
draw a more generic picture
so we're starting at some node
and let's say its parent is to the right
so it comes later in the order
for a while sorry get this backwards
we're doing successor
so it goes to left for a while
so these are all these nodes will come
earlier in the order because by the
definition everything in the right
subtree comes after
and at some point we have a parent
that's to the right meaning this node
was the left
child of this parent and that node by
definition will come
after all of the nodes in here
and could there be anything in between
node and this
uh this parent grandparent ancestor
only if there was something in this
subtree and we're in the case here
where there is no right subtree of our
original node
so this this is where all the nodes in
between node and here would be
but there aren't any and therefore this
is the successor
so that's sort of the general argument
why this
works i see a question yeah
placed into the traverse order so the
traversal order is never explicitly
computed
what we're taught it's always implicit
we can't afford to maintain
this as say an array this is just
in our heads maybe i will draw it with a
cloud around it we're just thinking this
okay it's not in the computer explicitly
in the computer all we store is this
and the reason is this is expensive we
don't we can't maintain an array of
things and be able to insert in the
middle
whereas this is cheap i can afford to
maintain this structure
and do all these things and so the
reason we're talking about these
operations is they're letting us
manipulate the order or in this case
letting us
iterate through the order so this was an
algorithm for iterating through the
entire order
but that takes linear time this was
getting started in the order find me the
first
first thing the order and this was given
one node find me the next one
how long do these operations take
right at most the height of the entire
tree in fact it's going to be
the depth of that first node but in the
worst case that's the height of the
entire tree
in general all of these operations are
going to be order h
we need to think about it in each case
except for this one which is order n
so iterating through the whole thing um
this in this case we're just calling
subtree first so
that takes order h time here we're
walking up the tree instead of down but
that's going to cost
exactly the height of the node we happen
to stop early but worst case order h
for all this all the operations we
consider today we just want to get an
order h bound
and later we will bound h so the point
is these are
fast if h is small like log n these are
almost instantaneous
whereas if i had to update the explicit
traversal order
say as an array i would have to spend
linear time every time i make a change
and yes it would be fast to do successor
if i had this stored explicitly
but maintaining it would be impossible
maintaining it efficiently would be
impossible
question questions
yes okay
cool um so these were queries
where i want to follow
see what's what's next in the traversal
sequence now let's talk about actually
changing the traversal sequence so these
are insert and delete operations
these will correspond roughly to insert
at or delete at
but they're not quite we're not quite in
sequence world yet
instead we're going to focus on
inserting or deleting in the middle
of a subtree
so i'm going to have two nodes
so the
in the traversal order
so node already exists in the tree new
is a new node that does not yet exist in
the tree hence i call it new
and what i'd like to do is insert new
right after node and there's a symmetric
operation which is insert before
it will be implemented almost
identically so we'll just focus on after
so i want to insert this new node in the
traversal order which again is in our
heads this is all
in in our thought bubble
that's what we want to achieve and we
have to do it by manipulating
this tree and however we change the tree
it defines a new traversal order
so maybe let's do an example first
actually i probably want this universal
order
keep track of that so uh
let's say the first thing we want to do
uh is insert
g before e
i want to illustrate both of the
operations
insert h
after e
a
okay um
so insert g before e so conceptually
what we want to do is insert g
here and the way so we're given the node
e
and we're given a sort of empty node i
mean a node that just contains g it
doesn't have any pointers yet
and we would like to put it before e
where should i put it
left child all right so that's
this is an easy case if i'm trying to
insert before and there's no left child
stick it there if i'm trying to insert
after and there's no right child
stick it there easy so let me write down
case one
so here we're inserting after so if
there's no
uh right child
put new
there okay i'm using informal language
here putting
this new node there
b instead of writing for example
node.write equals new
because that's only one operation you
need to do one thing you would do is set
node.write equals to new but you also
have to set new's parent to be
node.write
so instead of worrying about those two
pointer changes because we always do
bi-directional pointer changes i'm just
going to use
pseudocode and then in recitation you'll
see actual python code that does all
this
uh so then there's the other case
so that should be the second example
insert h
after a right
insert h after a so we already have a
node after a
in the right child in this right subtree
so where do i want to put
h relative to a
well it should be to the right of a but
it should be
before c it should be to the left of c
so that would mean we want to put it
here okay in this case it was pretty
easy because this tree was small
where do i want to put it in general
well wherever
subtree first tells me to put it right
subtree first is going to give me
the successor these are all kind of
parallel um
we're in the case now where our node has
a right child
and then successor tells us where the
successor is it is the first
node which is the leftmost descendant in
the
right subtree of the node okay a lot of
pointers to follow in that sentence but
it's
clear in the picture so this
in this case we had node and there was
no right child so we just added
new to be its right child okay in the
other case
we had a right child so here is node
there's uh there's this node here
node.right
which now we're supposing exists
and it defines a whole subtree there's
this one
which is the first node in the traversal
order of the subtree also known as the
successor of node
so i'll call this successor
of node in the current traversal order
but of course we'd like to make
new the new successor of the node so
where does it go
here
we want to add it as a left child
to the old successor
okay so put uh
node as
so take the successor and if you look at
the code for successor we're in this
case so we know it will just call
subtree first of node.right and remember
subtree first
went left as much as it possibly could
so what that means is this successor
node is guaranteed to not
have a left child right because it was
defined by going right once and then
going left as much as you could
so there's no more left which means we
can make one more left
just add new there and we're done
now if you look at the traversal order
it will be node then new
then the old successor and then the rest
of that subtree
okay it's kind of cool in all cases
uh i mean this was constant time
here we spent constant time after we
called successor successor costs order h
time
so this is order h
new new okay
put new there
clear okay that was insertion
let's do deletion
get the spec right and the example
all of these are going to have two cases
uh so let me
oh i didn't update so now h is after a
so it should be like this
you can check the new traverse order of
this tree is exactly that
next i'm going to do a couple of
deletions
let's delete
f first and then we're going to
well this is
confusing
and then we're going to delete a so
where's f we're supposing we're given a
pointer to f this node
well it's a leaf so if i want to delete
it i just erase it
easy leaves are easy to delete there's
no work to do so what that means is i'm
removing the pointer from d
to f okay we just erase that guy
uh okay now here's a trickier one
suppose i want to delete the root of the
tree this is kind of
the hardest case but in general it would
be somewhere in between leaf and root
so if i want to delete a if i just
erased it then suddenly there are these
pointers to nowhere
and i disconnect the tree into two parts
i don't want to do that i need to keep
my tree connected
so i'm going to play this trick
which is i forget if i use successor or
predecessor
so i'm going to uh look at a we already
have defined successor and
there by predecessor so i'm going to
look at the predecessor of a
which is e you can check that here the
one before
a is e this is in the left subtree
uh find me the rightmost item keep going
right until i can't that's e
so now these guys are adjacent in the
order and i'm about to remove a from the
order
so i can momentarily cheat and swap
their labels
i'm going to erase a and e here and put
e
after a why because it moves a
down in the tree and if i get to the
leaf i'm done
so i'm not quite done because this is
not a leaf so again i look at a's
predecessor it's now
g predecessor
we hope is always in the uh
farther down in the tree and then i swap
a with g
okay i have preserved the traversal
order except where a
falls just by moving a earlier in the
order here
and now a is a leaf and i can erase it
okay so that's what we're going to
follow now in actuality it's a little
tricky sometimes we need to use
predecessors sometimes we need to use
successor okay so the cases are
if the node is a leaf just
detach it from the parent easy
that's sort of our base case in the
recursion otherwise
there are two cases if
so if we're not a leaf that means we
have
a left child or a right child or both
both is going to be the easy case
but in general i have either there's a
left child
or there's a right child in either case
i'm going to be happy so i don't need a
both case
uh okay so what do i do in if i have a
left child
that guarantees to me that if the node's
predecessor
is inside that left sub-tree which means
it's lower in the tree
if i didn't have a left child the
predecessor would actually be higher in
the tree and i don't want to go higher
okay so if i have a left child i know
the predecessor is lower
and so i'm going to swap
my item the contents of my node
with my predecessor's item
and then i'm going to recursively delete
the predecessor okay that's the case
that we looked at in this code
in this example because we always had a
left child if we have a right child but
no left child we just do the reverse we
swap with our successors
item and then delete the successor in
either case we're going down
and so if we start at some node like the
route every time we do this operation
we're walking down and then we're
walking down
and in general we'll keep walking down
resuming where we left off which means
total amount of time we spend is
proportional to
the height of the tree in the worst case
question
right so e didn't used to have a right
child so we're changing identities of
nodes when we do this
because we uh this that we didn't
actually move this
circle the circle stayed in place and
what we changed was the item that was
stored in that circle
so whether you call this node e or a
it doesn't really matter it is just the
root note
okay so we're gonna play a lot of these
tricks of moving the items around so far
we hadn't been doing that we've just
been creating
nodes and placing them somewhere but now
we're
in this delete operation is the first
time where we're changing what's stored
in the nodes
but we still can define the traversal
order right the traverse order of this
tree is dbgehc
which should be what we get here if i
delete f and
a
and sorry can f
trees will not preserve connections
that's just the name of the game we are
we have to allow this otherwise we can't
do anything that's the short
version okay okay in the last few
minutes let me talk about how we take
these trees and implement a set
or sequence okay i've already alluded to
this
so for a sequence
we just make the traversal order
equal to the the order that we're trying
to represent
the sequence order
and if we're trying to source set items
with keys we're going to make the
traversal order
equal to ordered by increasing key
increasing item
key
some sense that's it but then we need to
think about how do we implement
all of these operations so maybe most
enlightening is for starters is
finding a key in a tree
so this is going to correspond to binary
search
if i'm searching for a key let's say i'm
searching for
g's key and i know this
may be hard in this example maybe i'll
replace these all with numbers
so i can think about key values
okay so let's say 1 7
12 17
19 and 23.
this is now in key order if you think of
the traversal order
the property is that all the keys in the
left subtree of the root
are less than the root and the root is
less than all the keys in the right
subtree and recursively all the way down
this is something called the
binary search tree property bst property
these here we're calling them binary
tree
sets or set binary trees but they're
also known in the literature as binary
search trees term you may have heard
before
so this is a special case of what we're
doing where we're storing the keys in
order
and then if i want to search for a key
like uh 13
i compare that key with the root i see
oh it's not
equal and it's to the left because it's
less than
17. so 13 is left of here 13 is right of
13 is right of 12 and so i know that
this is where 13 would belong
but there's no right child there and so
i know in find i just returned nothing
if i was doing find previous i would
return this note
because i have tried to go to the right
the last time before i fell off the tree
i was trying to go to the right and
therefore that last note i had was the
previous item if i was trying to define
next what would i do i would just take
this node and compute its successor
which we already know how to do and that
happens to be the root
okay so now i can do these inexact
searches when i do find previous and
find next
when i fall off the tree i find either
the previous or the next
and then with predecessor or successor i
can find the other one
okay so that's how we can do find and
find previous
and find next to do
uh sequences we need a little bit more
work
we'll do that next time
you