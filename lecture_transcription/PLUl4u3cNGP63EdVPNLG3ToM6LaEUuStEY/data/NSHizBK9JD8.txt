good morning everyone welcome to the
13th lecture of 606
just to recap from uh
last time
we've been talking about shortest single
source
shortest paths on weighted graphs for
the past
two lectures
previously we were only talking about
unweighted graphs
and so far up until today
we've talked about three ways to solve
single source shortest paths
on weighted graphs
namely the first one use bfs if you can
kind of transform your graph into a
linear size graph with
that's unweighted that corresponds to
your weighted problem
essentially
replacing each weighted edge with
of weights w with w
single edges now that's only good for
positive weight things
and if the sum of your weights are small
right but if the sum of your weights is
linear in the combinatorial size of your
graph
v plus e then we can get a linear time
algorithm to solve
weighted shortest paths using breadth
first search
then
we talked about
how we could if we if we
the the problem with weighted shortest
paths is if our weights were negative
and there could exist cycles then we
could have negative weight cycles and
that would be
more difficult to handle because then
you have
vertices where you have an unbounded
number of edges you might have to go
through
for a shortest path there might not be a
finite length shortest path so
but in the in the condition where we
didn't have cycles in the graph of
course we couldn't have negative weight
ones
so we are also able to do uh
that in linear time by exploiting the
fact that our vertices could be ordered
in a topological order and that we could
kind of push
shortest path information from the
furthest one back to the ones forward
right by relaxing edges forward by
maintaining this invariant
that we had shortest paths
as we were processing these things in
topological
order
then last time
we were talking about general graphs
graphs that could contain cycles and
this is our most general algorithm
because if there are negative weight
cycles bellman ford which we talked
about last time can detect them and in
particular
for any vertex that had a finite weight
shortest path
path
we could compute that a shortest path
for it
computed systems and for anyone that is
reachable from a negative weight cycle
not only could we
mark it as
minus infinity distance but we could
also find a negative weight cycle
essentially by duplicating our graph to
make it a dag and being able to follow
pointers back
in this
expanded dag that had multiple layers
okay so that's what we've done up until
now
we've gotten linear for some types of
graphs
and we've gotten kind of quadratic v
times e
for
general graphs ones that could contain
negative cycles now
how
bad is this well if the graph is sparse
right if if the number of edges in our
graph is on the order of v
then this is quadratic time and v right
v squared but if this is
if it's the graph is dense where we have
quadratic limit like the complete graph
where every edge is present then we have
quadratically many
edges in our graph in v and so this
running time is v cubed
v cube's not great in terms of its
running time we would like something
closer to linear
right and so that's what we're going to
do
today
if we have uh this restriction where we
have non-negative weights we can't have
negative weight cycles
right and this is a restriction that
comes up a lot
for many gra graphs you might encounter
right a lot of times you're uh you don't
have both positive and negative weights
right i don't have a negative distance
to my house right
in any metric we have non-negative
weights
right so
the these things come up a lot and we
can actually do quite a bit better since
there are no negative weight cycles we
can get almost linear
right it's not going to be quite
v plus e
as you see up here
on the slide we're going to get
something very close
it's v plus e but on the v term we have
this logarithmic factor in v which
remember for all intents and purposes
this log of that thing in real life is
not going to be bigger than like a
factor of 30 or something like that
right
maybe 60 but it's a it's a small number
and so
this is actually pretty good performance
it's almost linear that's what i'm
saying almost linear here and that's
what we're going to try to do today
so
how do we do this well i'm going to make
two observations here first off
our idea
is going to be to generalize the notion
of bfs right when we had bfs we split up
our graph
to solve unweighted short uh solve
weighted shortest paths with bfs we
could take our positive edge weights
break them up into individual
edges
but if the the total weight of our edges
was large
then we'd have a problem because now
we've expanded the size of our graph
right this is the same issue that we had
with something like radix sort where
we don't want our algorithm to run in
the size of the numbers in our input
we want our algorithm to run in the
number of numbers in our input right
this is the difference between n and u
right uh back when we were talking about
data structures here
if the size of our weights are large
compared to v and e
then
we can't doing this expansion is going
to be difficult but if we had
say some graph
this is my graph g
and we had a source vertex s
the idea here
is going to still be to try to grow
you know a frontier of increasing
distance from my source
and try to maintain all of the things
within a certain distance from my source
so that's the idea grow a sphere
centered at my source repeatedly explore
closer vertices
before i get to further ones but
how can i explore closer vertices
if i don't know the distances beforehand
right
this is kind of seems like a circular
logic right i'm going to use the
distance to my things to compute the
distances to my things that doesn't work
so well right
so how do we do this well the idea here
is to
gradually compute the distances compute
the distances as we go
so that we maintain this property now
this property this idea
wouldn't work
necessarily in the context of negative
edge weights
right here we have this
growing frontier this ball around my
source
and
as i grow my thing
these things are at further and further
distance right because any edge from
something
back here as i'm growing my ball of
certain distance these things are
outside that distance right we're kind
of using
a key observation here here's my
observation one
uh
if
weights
uh greater than or equal to zero
then
distances
increase
along
shortest paths
maybe maybe weakly monotonically
increase right
if there are zero weight edges but in
general if i had a path going from s
to
to some v
and it's going through some
vertex u
right i have some shortest path this is
the shortest path from s to v
and it goes through some point u some
vertex u
then this monotonicity more specifically
means that
the shortest path from
s to u
and the shortest path from s to v
which is this whole thing
right
how do these relate to each other
if this is along that path
then this has to be at least as large
as the sub-path right because all of
these the weight of this path cannot be
negative
so that's the thing that dijkstra is
going to exploit
it essentially means that when i'm
expanding this frontier
of distance away from x
it's possible if i had negative weight
that
this line
if i had some very negative weight going
from a vertex here to a vertex here
this vertex
could be within
this boundary
maybe maybe if this distance is x this
guy could be within x right my my
the
the things that are within distance x of
s might not be all contained there could
be a path from
here to this
other vertex with distance x
that doesn't have this property because
i could decrease in distance along the
path
okay so that's the first observation
second observation
well let's see if we can piggyback on
dag
relaxation right
i claim to you that
we can
solve
single source shortest paths faster
if we're given
order
of
vertices
in
increasing
distance beforehand
distance from s
right so here's the idea i'm not going
to give you the distances to all these
vertices
instead i'm going to give you the
order of the vertices in some increasing
distance
from s
okay so basically i'm saying if i had
some i don't know here's a graph uh
let's see if i can remember
okay
okay and i'm gonna put some edges on
here
okay and i'm going to call these
vertices
0 1 2
3 and 4. okay so here's a graph
maybe i put some edge weights on here
i'm going to say this one is
this one is 2
this one is 3 this is
this is 1 this is 0 and this is 0.
so
from vertex one two
two uh that was a two for
the labeling of that vertex
that edge is zero weight okay so here's
a weighted graph
okay and i don't necessarily know
i could use bellman ford to find
shortest paths from this vertex
zero
right
but the idea here is i'm not going to
give you shortest paths i'm going to try
to compute shortest paths but i'm going
to give you some additional information
i'm going to give you the order of their
shortest path distance
from the source
and i can just i'm going to eyeball this
and say
i'm going to change this slightly to
make it a little bit more interesting
i'm going to say this
is
distance 4
okay
all right so now what we have is
the shortest path distance i'm just
eyeballing this the shortest path
distance
to
ah bad example
all right so
these are the weights
shortest path distance to 3 is going to
be 2 i'm going to say
through there
shortest path distance here is two also
shortest path distance here is also two
because i can go through both of these
zeros and
it's not a problem and then the shortest
path distance here is two to here and a
third to there okay so these are
listed in increasing distance
from my source
okay i
i had to compute those deltas to
kind of convince you that this is the
right ordering but this is a right
ordering of these things now it's not
the only right ordering
right
but it is a right order okay so i'm told
i'm i'm arguing to you that i could
solve single source shortest paths
in linear time
if i were to give you the vertices in
increasing distance how could i do that
well
it because of this first observation
i know that if these are increasing in
distance
any edge going backwards with respect to
this ordering
can't participate in shortest paths with
one exception
anyone know what that exception is no no
edge can go backwards in this ordering
based on this observation
except under what condition
yeah
if the weight is zero yeah so if the
weight is zero just just like this
situation here
then i could go backwards in the
ordering
seems problematic right the idea is i'm
going to want to construct a dag
so that i can run dag relaxation
well
if i have a
component here
that has zero weights
i can kind of
coalesce this thing down
i can i can deal with this this this
component separately
right
let's let's worry about that separately
if we do
we can kind of collapse this edge down
into a single vertex
and transform this graph so it does
respect the ordering okay so i'm going
to transform this
graph
into
a new graph
this is a graph
contains vertex 2 and vertex 0
vertex
1 and 3 here
and vertex 4.
okay now we have
uh and i'm only going to keep edges
going forward in the
ah
i'm going to need to collapse this
entire section
right this entire section
down into one vertex this doesn't quite
work
okay
let's let's ignore uh
zero weight edges for now let's assume
these are
all right there's something broken here
if i have a cycle here
yeah
right now i don't have a cycle of zero
weight
right so what i could do is i could take
this vertex
and put it after both of these vertices
and now i would or
i could rearrange the order of these
three vertices where there's a path of
length zero
and get a new ordering that still
satisfies the property
okay
and that's always the case
because uh paths
uh
can't increase
path can't decrease in in weight i can
rearrange the ordering of these things
so that
three comes first
one comes second and two comes third
of those three vertices okay
yeah so for for every set of
uh
zero edges i can just
flip the relationship if they have the
same distance okay in my input
i'm given vertices that have the same
distance from the source and so if those
are the same distance from the source
and they're connected by zero eight edge
it doesn't hurt me to flip their
ordering so i'm gonna do that okay
so let's
convert that into a graph with a
different ordering
zero
three now one
two
okay and i have this distance this edge
this edge this edge this edge
this edge
what am i missing two to three
and
here
i think i have all of those edges
yeah
okay
now i have the property that
every edge that could participate in the
shortest path are going forward in the
ordering
right because
all of these
are zero weight
so we flip those around so they're going
correct with respect to the ordering
and any
edge going backwards that is positive
weight
certainly can't be used in any shortest
path so i'm just going to get rid of
them
yeah what do i do if there's a zero
weight cycle
if there's a zero weight cycle i can
just coalesce them all together down to
a single vertex because if i reach one
of them i can reach all of them
okay
exactly i'm computing a topological so
the idea here is we're trying to
construct a dag
i can construct this dag in linear time
and then i can run
dag relaxation on this graph
in linear time to get shortest paths
so that's
that's an approach if i knew the
ordering of the vertices in increasing
distance
then i could use dag relaxation so we're
going to use both of these observations
that's how we're going to solve this uh
single source shortest problem
with non-negative weights using dijkstra
so that's
finally now where we're coming to
sorry i missed a case here when i was
writing up my notes and i'm trying i
tried to fix it live and hopefully you
guys followed me
okay
dijkstra's
algorithm
did i spell that right
kind of
okay
what
dix
styx
draw
okay
now dykstra
was this dutch computer scientist
okay this is him
pretty famous he he wrote a monograph on
why
uh programming languages should uh start
with
zero indexing as opposed to one indexing
so i like him but uh in particular he
designed this very nice generalization
of bfs for weighted graphs
uh but maybe i didn't spell this right
because when he writes his name he
writes it with a y with a dash over it
so
in re in reality
on a dutch typewriter
you might have a a character that looks
like this y
with a new loud on top of it
but on a modern
on a on a english keyboard
this looks
pretty similar to an ij
so
in a lot of manuscripts
we write it as
d i j there's no j sound in dijkstra
it's coming from this this y here okay
so that's a interesting way to remember
how to spell dijkstra
but the basic idea behind dijkstra is
the following
idea
relax
edges
from
vertices
in
increasing
distance
from
source okay this is the same kind of
difficulty we had before when we were
trying to you know
generalize bfs
so how do we know
what the
next
vertex is with increasing distance to s
well the second idea is
find
next
vertex
efficiently
using a data structure
okay and the data structure we're going
to use is something i like to call
a changeable priority cube
okay so this is a little different than
a normal priority queue
that we had
uh at the end of our data structures
uh unit
this changeable priority queue has three
operations
we're going to say it's a
queue
we can build it
on an iterable set
of items just
stick
x uh like n items in there
we can
delete min
from the queue
okay this is the same now as the
priority queue it's this third operation
that's going to be different
decrease
the key
of an item that has id id
okay so this is a little strange
what the heck is this id
all right with the changeable priority
queue
each of our items has two values instead
of one value it has a key
but it also on which the priority queue
is
deleting the min
item
with the minimum key
but also each item has an id associated
with it a unique integer
okay so that
when we perform this operation decrease
key
it can find some
item in our data structure with a given
id
and if it's contained there it's going
to change its
key
to some smaller value okay
okay
and
don't worry about the edge cases here
we're always going to make sure this k
is going to be smaller than whatever
that key was to begin with all right so
this is a really a kind of a funky
operation
if i had a priority queue
not a changeable priority queue but i
had a priority queue and i wanted to
implement a changeable priority queue
how could i do it
well
a regular priority queue is already
going to get me these two operations
it's just this one i essentially need to
find something by a id
and then update its key
okay so the idea how to implement
this is going to be to use a regular
priority queue
i'm going to call it q prime
and i'm going to cross link it
with a dictionary d
okay
so this is just a regular priority queue
on my items that has the key as defined
above right
but i'm going to cross-link it with a
dictionary a dictionary that maps ids
to their location in the priority queue
we've done this many times in the data
structures
section we're trying to cross-link to
data structures to make
a query on a different type of key
to find its place in another data
structure okay
so
if we had a priority queue in a
dictionary
we could do this stuff
pretty fast
okay
in particular i'm going to assume that
our ids of our vertices
are the integers between zero and v
minus one and so for my dictionary
i could get constant time looking up of
that id
by using what data structure
we could get okay so we could get
expected constant time
if we used a hash table
but if we knew that our
vertex ids were just the numbers from 0
to v minus 1
we could get a rid of that expected time
by using
a direct access array
great okay so that's what the assumption
and so really the name of the game here
is to choose a priority queue here
that's going to make these things fast
when we start to look at dijkstra okay
so we're going to use this
data structure
to
keep track of
our distance estimates to all of the
vertices
away from s okay so this is dijkstra's
algorithm
okay set
so same initialization step
we're going to set our this is a
estimate d not delta
we're going to want the d's to be our
deltas at the end of the algorithm
that's what we're going to have to prove
so we first set all of them to infinity
and then
set
d of ss
equal to zero
right
and here we're never going to update it
again right because
our shortest distances in a graph with
non-negative edge weights
certainly can't go below zero okay
all right
now we build
our build our changeable priority queue
queue
uh
with
an item
i'm gonna say an item
is uh
x is represented by a tuple of its id
and then it's key
just for brevity here
okay with an item
v
d of sv so i'm going to be storing in my
changeable priority queue the vertex
label
and its shortest path distance estimate
d right and that's going to be the key
the minimum that i'm trying to going to
be querying on
for
each
[Music]
v and v
okay
so i'm going to build that thing it's
going to then have all of my vertices in
my graph
then while
my changeable
priority queue still has items
not empty
i'm going to delete
some
u
d
s u
so some item
such that its
distance is minimized right
from
q
that
has
minimum distance
okay so i'm going to remove i'm going to
look at all the things in my priority
queue at the start it's just going to be
s right because everything has shortest
path distance estimate infinite except
for s and so that's clearly the smallest
okay so i'm going to remove that from my
queue and then i'm going to process it
okay how am i going to process it
it's the exact same kind of thing as dag
relaxation i'm going to relax all its
outgoing edges right so
just for completeness for
v
in
the outgoing adjacencies
of u
i'm going to
relax
oh sorry
we have to check whether
whether we can relax it right
basically
if
d the shortest path distance estimate to
v
right
is
greater than
going to
u first and then
crossing that edge
right
if going through that is better this
this is violating our triangle
inequality
and so we relax
edge
u v
and by that we mean
sets this thing to be equal to that
thing
right that's what we meant by relax and
then we have one other thing to do we've
changed these
distance estimates
but our q doesn't know that we change
these things right we added these items
in here
right
but it doesn't know that my distances
has changed right so we have to tell the
queue to remember
we uh to change its
key value
associated with the item v
right
so
decrease
what is it decrease
key
vertex v
in
q
to
the new
s
v the one that i just decreased here
right and i know that i decreased it
because i set it to a smaller value that
makes sense
all right so that's
dijkstra
let's run it on
an example
okay so here's an example
i have a
directed graph it does contain cycles in
particular here are some cycles
i think those are the the main ones
okay there are definitely cycles in this
graph
and but as you see all of the weights
are non-negative in particular they're
positive actually it's going to be just
helpful in
in writing out this example so let's run
dijkstra on this
graph okay first we initialize and we
set the shortest path distance i'm going
to label it in white here
to all of the things and i'm going to as
i update it i'm just going to cross them
out and write a new number okay
so that's what it is at the start right
that's initialization that's after step
one
and then i stick things into my queue
what's in my queue here's my q
right it's everything
right it's vertices
s a b
c d
okay
i got five items
in my queue
really it's the item pair with its
shortest distance estimate i'm just not
going to rewrite that here okay
so the idea here is what's the the while
loop okay q is not empty great
we're gonna delete
the one with the smallest distance
estimate which is
s right yeah
so i remove that
and then i relax edges out of s right so
i relax edge
here
to a
that's better than the distance estimate
10 is better than the distance estimate
infinite so i'm going to
change this to 10.
and then here's another outgoing edge
3 is better than
infinite so
i'm going to change its delta to 3.
okay so now i go back in here
and i change the distance estimates
associated with my q
okay
now next step of the algorithm
s is done
right i've processed everything
distance 0 away
but i'm now going to use my priority
queue to say
which of my vertices has the shortest
distance estimate now
so which one is it
a b or c or d
yeah it's three c right three is smaller
than 10. so
q is going to magically delete c for me
tell me what that is and now i'm going
to process that right i've now changed
my boundary
to this
okay and now i relax edges
out of c
so
here's an edge out of c that's a 4
a 4 plus the 3 is smaller than 10
so i update it
3 plus 8 is 11. that's smaller than
infinite so i update it i relax
3 plus 2 is smaller than infinite so i
relax that as well
okay
now of the things still left in my queue
i'm actually going to
remove it from my queue instead of
crossing it out maybe that's better
of the vertices still left in my queue
which has smallest distance
yeah d
d has five seven or eleven five is the
smallest so i remove d from my q and i
relax edges from it
and now my
boundary looks something like this
okay
i relax edges out of it five plus five
that's ten ten is smaller than eleven so
that's
a ten
and that's the only outgoing edge from d
so i'm done okay and then the last seven
is smaller than 10.
i relax edges out of a
right
a
to b
seven plus two is smaller than ten
and now i'm done so what i did every
time i
removed s or i removed a vertex i set
its shortest path distance to the
small the the last value i assigned to
it so this was then three
and then a was seven
b was nine
and then d was five
okay
so that's dijkstra in action
it seems like
these are the shortest path distances
but how do we prove that did it do the
right thing
well let's find out
so that's what we're going to spend
some time on right now is talking about
the correctness of dijkstra's algorithm
okay correctness follows from
kind of
two main observations
okay so the the claim here that we're
trying to prove is that
d of s
equals the delta
s so the estimates
equal the shortest path distances
at the end of dijkstra
for all
v and v
at
ant
all right
and this is going to follow from two
observations so the proof
here
first
if ever relaxation
sets
d of s of v it sets the estimate equal
to the shortest path distance
if it ever does that
i argue to you
that
still
true
at
end
okay that's not a very strong statement
right this is saying if i ever set the
the distance estimate
to the true distance
i'm never going to set it to a different
value later on
and why is that
well
relaxation
only ever decreases the distance right
relaxation
only decreases
dsv
but
we proved in lecture 11 so two lectures
ago that relaxation is safe
and what is safe mean
safe means that
relaxation
that these relaxation will only ever
change these distance estimates
to
be either
infinite right it was never there was
never a path
to my
my vertex or
it was the length of some path to v
length
of
some
path
okay so what does that mean
it only decreases
but it's always the length of some path
to v right so if this is the length of
the shortest path to v i could never set
it to a smaller length
right because there are no paths with
shorter distance that's the kind of
little point okay so with this
observation
i i'm gonna argue this final claim
it suffices to show
that
my estimate
equals the shortest distance
when
v is removed
from
the queue
okay
and since i remove every vertex from the
queue
in this while loop
i will have eventually set all of the
distance estimates to the real distance
and will be golden
happy days all right so we'll be done
if we can prove that statement all right
so we're gonna prove this by induction
obviously
production
on
first
k
vertices
removed
from
the queue
all right so the q
we're we're popping vertices from this q
in some order
so i'm going to just argue that this
claim is true for the first k
right
clearly that's true for k equals 1
base case
k equals 1
right what is k equals 1 that means the
first vertex that i pop has this
property which is definitely true
because we set
the shortest path distance to s to be
zero that's all good
okay
now we have our inductive step
okay
assume it's true
true
for
k prime
sorry k less than
k prime okay
and let's let
v prime
be
k prime
vertex pot
okay v prime
okay
and now let's look at some
shortest path
from s
to v prime
so we got the shortest path
from s to v prime
it exists v prime is
accessible let's say we pruned our graph
to be only the things accessible from s
so that
yeah there exists a shortest path
to v prime okay
and now let's think about
these vertices
some of them
were removed from the queue
and some of them were not right s was
definitely removed from the queue
right
but
some of these other vertices might not
be
right i want to be able to induct on
this path in particular
the vertex before me
so that i can say that when i removed it
and i relax the edge to v prime
then we're all golden right
but that might not be the case there
could be a vertex the vertex preceding
me in the graph in this shortest path
it was not popped from q i need to argue
that it was or some other thing okay so
let's
consider
the first
vertex
in this path from s to v
i'm going to call it
y i think
a vertex y
that is not in q
right
after i pop v prime this is the first or
before i pop v prime
y is not in the queue now these might be
the same
vertex right if all of the preceding
ones on this path
are
were in the queue
but in particular
we're going to look at this guy okay and
say its predecessor's x in the path
well what do i know
i know that x is in the queue right
everything
here
was
was popped from the queue
not in
right
which means that by induction
the shortest path
distance was set here correctly
so that the
the distance estimate at y
can't be bigger than
the shortest path to x
plus
w
x y
okay
but this is on the shortest path to y
right because sub paths of
shortest paths are shortest paths so
this has to equal
d
s y right the distance to y so actually
y is all good here right and so if v
prime were y we'd be done
right that's the same argument as dag
relaxation
but we need to prove something about v
prime
well because we have non-negative
weights the distance to v prime
has to be at least as big as this
distance right because it's a sub-path
right so this has to be less than or
equal to the true distance
to
the prime
right because
of negative uh non-negative weights
right because the weights are
non-negative
but because relaxation is safe
we know that our distance estimate for v
prime has to be at least the shortest
path distance right
right this is because it's safe
this is
weights are
uh
greater than or equal to zero
right
the last step here
is that
because we're popping the minimum from
our priority queue
right the thing with the smallest
shortest path distance
this has to be less than or equal to
the shortest path distance estimate to y
right because this is the smallest among
all such vertices in my queue
but these are the same value
so everything between here is the same
value in particular
the estimate here
is equal to my true shortest path
distance which is exactly what we're
trying to prove okay so that's why
dijkstra is correct
and spend the last five minutes on
the running time of dykstra
well we set this up
so that we did everything in terms of
this
these q operations
right so we have these q operations we
have three of them
i'm going to say if i have
a build operation let's say it takes b
time
delete min i'm going to say it takes m
time and this decreased key i'm going to
say it takes d time
okay so what's the running time of
dijkstra if i take a look at that
algorithm over there
well i guess
let's switch these back up again
okay so what does this do we build once
right
then we delete
the minimum from the queue how many
times
v times right we remove every vertex
from our q
then
for every possible edge
we may need to relax
and decrease the key in our queue
once for every outgoing edge
okay
so the running time is
b plus
v times
m
plus
e
times
d
right
okay
so how could we implement this priority
queue well
if we use the stupidest priority in the
world
here's here's a list of different
implementations we could have for our
priority queues
and when i say priority queue i mean
this priority queue
we're already implementing the
changeable priority queue by linking it
with a dictionary that's efficient okay
if i just use an array
i can find the min in linear time sure
and i don't have to update that array in
any way
i mean i can just keep the distances in
my direct access array i don't have to
store a separate data structure i just
store the distances in my direct access
array d
and so i can find it in constant time
and i can update the values stored there
and then whenever i want the minimum i
can just loop through the whole thing
right so that gives me a really fast
decreased key
but slow delete min but if we take a
look at the running time bound here
we get something if we replace n with v
we get a quadratic time algorithm
in the number of vertices which
for
a
dense graph this is in linear time
that's actually pretty good dense
meaning that i have at least a quadratic
number of vertices
so that's actually really good and it's
the stupidest possible
data structure we could use for this
priority queue
now we can do a little better
actually for not dense i mean for sparse
graphs where the number of edges is at
most v
then
this is pretty bad it's quadratic right
we want to do something a little better
now if we're sparse a binary heap
can delete min
in
logarithmic time but it can actually if
i know where i am in the heap
and i decrease the key
and i'm in a min heap
right
i can just swap with my parent upwards
in the tree in log n time and free
rebalance the refix the binary heap
property and so i can do that in
logarithmic time
okay and if i do that and i put it into
this formula
i actually get n
or v
plus v times log v
plus e times log v
right and so that's going to give me
e log v if i'm assuming that i'm first
you know pruning out all of the things
not connected to me then e
asymptotically upper bounds v and i get
this e log v
running time which is pretty good
right that's just an extra log factor on
linear
now there's a even better well better is
is
is hard to say
really there's a different data
structure that achieves
kind of both bounds for sparse and
dense graphs and everything in between
it gives us an e plus v log v running
time bound this data structure is called
the fibonacci heap we're not going to
talk about it in 6.06
they talk about it you can look at
chapter 19 in clrs or you can look at i
think they talk about it in 6854
if you're interested in learning about
fibonacci heaps but these are almost nev
i mean they get good theoretical
uh bounds so what you want to say
is whenever we give you a theory problem
where you might want to use dijkstra
you want to use this theoretical
running time bound
for your problem
a plus
v log v but if you happen to know that
your graph is sparse or dense
just using an array or a heap is going
to get you just as good of a running
time very close to linear
right and so in practice
most people when they're implementing a
graph search algorithm they know
if their graph is sparse or dense and so
they never bother implementing a
fibonacci heap which is a little
complicated okay so they are usually
either in one of these first two cases
where v squared is linear because when
your graph is dense
or
you know we're very close to linear e
times log v
which is v log v if your graph is sparse
okay so that's
uh
the running time of dykstra
okay
so
so far
we've gotten all of these nice bounds
right
some special cases where we're
i mean special cases where we're linear
dijkstra where we're close to linear
and bellman ford you know if we throw
our hands up in the air
there might be negative cycles in our
graph
we got to spend that quadratic running
time bound now there are faster
algorithms but this is the fastest we're
going to teach you in this class now
in the next lecture we're going to be
talking about all pairs shortest paths
and we'll pick it up
next time