all right welcome to the grand finale of
dynamic programming in 6006
four of four today we are going to
focus in on a particular type of sub
problem that we saw at the very
beginning with fibonacci which is when
you have an integer input and a natural
thing to do with that integer input is
look at smaller versions of that integer
and this is going to lead us to a new
notion called pseudo-polynomial time
we've talked a lot in this class about
polynomial time being a good running
time
but pseudopolynomial is a pretty good
running time and we'll talk about that
and it relates to these integers
we'll only look at two exam new examples
rod cutting and subset sum
but then we're going to review all the
examples we've seen from kind of
diagonal perspective so uh as usual
we're applying our swordbot framework
with subproblems
relations topological order base cases
original problem and time
quick review uh we saw
so the hardest part is getting the right
set of sub problems
uh and there are some natural choices
for sequences we try
prefixes suffixes substrings for
integers like in fibonacci
there's a given number and you want to
compute that at the nth fibonacci number
what we ended up doing was solving
fibonacci numbers for
all input numbers input integers between
0 and that number n or in this case
capital k and that's a general technique
and we'll see two more examples of that
today
otherwise we take products of these and
often that's enough but sometimes we
need to add more sub problems in what we
call sub problem expansion
often with extra constraints that let us
remember some state about the past
my canonical example that is the piano
fingering where we had to remember what
our fingering assignment was
in some sense from the previous step in
order to compute the transition cost
and this is very powerful technique you
can also use it to like
play super mario brothers optimally if
you have a constant size screen and all
you need to remember is what's in the
constant size screen
if everything outside that screen resets
you can just add that
state as a parameter to your sub problem
and you'll be able to
solve solve super mario brothers
anyway very very useful and that was
sort of the focus of last lecture we
won't talk about it
much here today and then
we relate these sub problems recursively
and this is basically the test of
whether your sub problem definition was
correct is can you write down a
recurrence relation
which is just a recursive algorithm and
there's a nice general procedure for how
to come up with these relations which is
to just
think up some question about the
sub-problem solution that if you knew
the answer reduced to smaller
sub-problems
and then you just locally brute force
all the answers to that question
which i like to think of as guessing the
answer correctly
and then just directly calling the
recursive things but then at the end
you have to pay for that guess by
looping over all possible guesses in
order to guarantee that you actually
find the right one
so once you identify this question it's
very easy dp is all about
just brute force anything that you want
and usually that leads to pretty good
running time as long as the number of
possible answers to that question is
polynomial
then we need to check this relation is
acyclic
and then it it's often reduces to
finding a path
like a shortest path or something in a
dag the subproblem dag
uh we need some base cases we need to
make sure we can solve the original
problem using one or more sub problems
and then we analyze the running time as
usually a number of subproblems times
the amount of non-recursive work in the
relation
plus however much time it took us to
solve the original problem
okay so that was our framework we've
seen it four times now
slightly refined each time we've mostly
added some
general techniques for sub problem
definition
and how to write relations
so let's do a new example which is rod
cutting
this will be pretty straightforward but
it will serve as a contrast to the next
example we talked about subset sum
so what is the problem the name rod
coming comes from
the book clrs but it's
actually a pretty practical problem
maybe not for cutting rods
but you could imagine you you have some
resource
of a given length i like to think
because i have been uh
wood hardwood shelf shopping recently i
like to think of you have a big plank of
hardwood
and you get some price for selling that
length but you could also cut that plank
into multiple pieces of various lengths
that sum to l
and you could sell them individually
maybe you make more money that way
that's what this problem is all about so
you're given the value
of every possible length you could cut
we're going to assume
all links have to be integers and scale
so that that's true
so capital l here is the original length
little
l is a candidate length of a piece you
might cut
and v of l is the value for cutting off
a length uh l rod sub rod
and we're going to assume when we cut we
don't lose any material
uh you could probably adjust for that
but it's not terribly interesting
and we want to know what is the best way
to split up our
big rod of length capital l into various
rods of small l length different
potentially different lengths
so i'll call this the max value
partition
in mathematics this is called partition
a bunch of numbers that sum to a given
number
and we want to maximize the total value
naturally
so here's an example
let's say our original length is seven
and we have this table
for lengths one two three four five
six seven all the different lengths i'm
going to write down
a value that's an integer
cutting off a route of that length and
selling it select
sell price
it's presumably monotonic but doesn't
have to be
maybe people really like buying powers
of two length or something and so those
sell higher so it doesn't have to be
monotonic but in this example it is
and so i have this route of length seven
and i could sell it directly for 32
dollars let's say
but i could also split it into say uh
one a length one rod and a length six or
a length
one rod and two length threes or a
length three and a four
anything that sums to seven and
probably the most natural thing to do
for this problem is like a heuristic
this would be a greedy
bang for buck heuristic is what it's
usually called is to take the ratio
how much money do i get for a given
length divide v of l by l
and try to maximize that that would sort
of be if i had to pick a single item and
sell
many of that type that would be the
optimal thing to do so this has a ratio
of one that's bad this has a ratio of
five
that's better and you stare at it long
enough
i believe six is the best
has the highest ratio slightly more than
uh i can't divide
um slightly better than um
let's see slightly slightly worse than
four or was fourth the best
slightly worse than four what do you
mean
oh slightly i see the ratio is slightly
less than four thank you
yeah uh which all of these others are
somewhat worse for example two uh if i
double
the 3 value i get 26 which is quite a
bit less than 31
and i guess the the closest competitor i
think is 2
because if you multiply this by 3 you
get 30. so if i sold three
twos i get 30 but if i sell one six
which is the same quantity
i get 31 so slight improvement
and so this this item maximizes bank for
buck
that ratio and so one natural partition
is six plus one
i sell one rod of length six and that
leaves a rod of length one
and this will give me uh 31
for the six and one dollar which gives
me
32 dollars uh but this turns out to not
be the best
which is actually the same as if you
just sold it outright
but in fact you can do better by selling
this is not obvious
stare at it for a while a three and a
four
also sums to 7 then we get 13
plus 18 which is
hopefully bigger 33 30
get this right nope i did not get it
right
uh that's too small
uh we're going to take these two and
sell 3
plus 2 plus 2.
then i get 13 plus 10 plus 10 remember
two was a close competitor first
for the ratio for six so it's a little
better to sell twos
two twos and then a three because then
we get thirty three dollars
and that turns out to be the best for
this problem and it seems really
tricky to figure this out in general
there are
exponentially many different partitions
can't afford to try them all
question can i have negative values
can i have negative values in here uh i
think
that will work fine i'm not allowed to
have negative lengths or zero lengths i
don't want zero length to actually give
you something because then i just
cut infinitely many zeros but uh the v
of l i think could be negative
yeah do i have to use a whole bar
uh in this problem yes
i think it wouldn't change much if you
didn't have to use the whole bar we can
think about those after we write the dp
so um let's
solve this with sort bot
so what's the input to this problem well
we have
uh i didn't mention this is an integer
length
positive integer length
so we have one input which is an integer
l and we have another input which is
i guess it's like an array of integers
so this is a sequence
and this is an integer so if we look at
our
list of nice sub problems we could try
prefixes or suffixes or substrings of
the value
structure or we could try
for that integer smaller integers that's
actually what i prefer
i think the way to think about this is
to jump ahead to what do we want to
what feature of the solution do we want
to guess
and presumably we should think about
what is
some length of rod that we will cut and
sell
okay so i have this big rod maybe i sell
the whole thing maybe i cut off a thing
of size one and sell it maybe i
cut off a thing of size two and sell it
um but i have to sell
something unless i'm not selling
anything
and so uh that's there's only n
different or
there's only l different choices for
what uh
rod lengths to cut off first and so we
can just brute force that
in order l time so what problem do we
get
if we cut off an integer of some small l
length
well we just get the same problem with a
rod of length capital l minus small l
the values don't change
it happens that i won't use the big
values if i cut off some amount of the
the problem but i like to think of this
as we're just all we're doing is
decreasing big l
and so my sub problems are going to be
uh for each small l
less than or equal to big l solve that
problem
so x of l is max value partition
of uh length
l little l for
little l equals zero one
up to big l okay so just same problem
but with different choices for big l so
this is using
this integer sub problem now in this
example that happens to correspond to
prefixes of the v
array because if i only have length up
to little l
that i really only need the prefix of
the value array up to
little l so you could think of it that
way that's also fine
but i think this way is a little more
generalizable
okay so i claim this is a good set of
sub problems because
i can write a recurrence relation which
is
actually pretty simple
like i said
uh we want to choose
some piece so we're given a rod of
length little l
i want to choose how much of that rod to
sell in the next piece so i could cut
off
something of length one or i could sell
the whole thing or
cut off any piece size in between
and the money i will get for that is
whatever the value of that piece is
plus recursively the maximum i can get
from all the remaining pieces sorry from
the remaining length which is
little l minus p
okay so very simple inside the formula
just the value for the first piece we're
guessing what is the first piece we'll
cut off and sell
we get the value for that piece and then
recursively
we see what's the best we can do with
the remainder now we don't know what
size
the first piece should be so we just
brute force it we try all possible
choices for p
and take the max that we get out of this
formula
over that choice and that's guaranteed
to find the best overall
because we must cut off some piece now
if you wanted to allow not selling
anything
in the case of negative numbers you
could just add a
zero to this max and then you might stop
early if there's nothing left
that's worth selling
okay topological order is very simple
we just have these capital l different
problems
and if you look at oh uh
yep so we're looking at l minus p p is
always at least one
so we're always strictly decreasing l in
this recursive call
and so as long as i solve the problems
in order of
increasing little l i'll guarantee
that whenever i'm solving x of little l
i'll have already solved all the things
i need to call
so if you're writing a bottom up dp this
would just be the for loop
l equals zero up to big l
in that order
this is equivalent to the statement
but the key is to check that this is
acyclic because we're always referring
to smaller
l and so increasing l is a valid
topological order
in this sub-problem
uh dag defined here
where there's an edge from an earlier
thing to evaluate to a later thing to
evaluate
okay base case
would be x of zero
that's the first thing we'll want to
compute here and indeed this formula
doesn't make much sense if i have
x of 0 because i can't choose a number p
between
1 and 0. even non-strictly
and so what does it mean well if i have
a rod of length 0 i can't get any money
out of it
so that's it it's a 0.
that's an assumption but a reasonable
assumption you don't get something for
nothing
okay then we have the original problem
which is just
the length l rod
and then the time to compute this thing
how many sub problems are there capital
l plus one so we'll say
theta l sub problems
and we'll multiply by uh
the amount of time to evaluate this max
just a constant number of things in here
not counting the recursive call and so
it spent
takes little l time little l is
certainly at most big l
and so we'll say big o of big
l time it's actually a triangular number
but it will only affect things by a
constant factor
so we get l squared time
and we're done so very simple
straightforward dp at this point we've
seen much more complicated examples than
this
but it highlights a question which is
is uh
theta l squared polynomial time
so is this a reasonable running time and
i
claim the answer is yes this is a
reasonable polynomial running time you
might say well of course it's a
polynomial look this is a polynomial
l squared that's a quadratic polynomial
but it's a quadratic polynomial in l and
we haven't really thought about this too
hard but
what does it mean to be polynomial time
um
and this is a notion that's properly
called strongly polynomial time
we won't worry about that strongly too
much
in this class but if you look this up
online you'll see the difference
polynomial time means
that the running time is polynomial
in the size of the input
and the size of the input is
for our model measured in words
machine words remember our good old word
ram w bit words
it's been very useful because it lets us
assume things like adding two numbers
is constant time as long as these
numbers fit in a word as long as they're
at most w
bits and generally we assume all the
things we're manipulating
fit in a machine word because that's
what the case where we
normally work and so the natural way to
imp
to measure the size of an input so in
this example
this problem rod cutting the input is a
single number l
and this value array v of l which is
capital l numbers so i would say
n integers and we've generally assumed
didn't mention integer value here
as in throughout this class we assume
that all the integers unless otherwise
specified
fit in a word so we've got one word here
and l
words here so the total size of the
input to this problem
is l plus one integers in this problem
input size is
l plus one which we can think of as just
l that means theta l
okay so i explicitly didn't want to use
n
in this problem because usually we use
the letter n for the problem size not
quite always
but input size always means input size
and so here we can compute it
in terms of the specification it
involves l plus one
word inputs and so polynomial time
should be
polynomial in that input size in l plus
one in our example
so of course l squared is polynomial and
l plus one
so good yes
okay the next example i'm going to show
is going to be very similar
but the answer will be no make it more
interesting
but it'll still seem pretty reasonable
so we'll come back to that
issue in a moment let me first show you
uh what the subproblem dp looks like for
this problem
again took me a while to draw so please
admire
so this is the same example of of these
values 1 10 13 18 20 31 32
drawn here on a graph it's the complete
graph
oriented uh in this increasing
way i think this is called a tournament
in graph theory
uh so we have the base case over here uh
this corresponds to a length zero rod
where we get no money
and over here we have our full rod of
length seven and
i claim the best that we can do is uh 33
and what's happening here is for every
value like three that i could sell a rod
of length three for 13
there's an edge that goes from each
vertex
to 1 3 higher
and those all have a weight of 13 on
them
and then what we're essentially trying
to do is find a longest path from here
to here
longest because we want to maximize the
sum of values that we get
and we know if we negate all the weights
that's the shortest path problem so we
could solve that with shortest paths in
a dag
but i've drawn here the shortest path
tree from
the base case um so it actually tells us
that
if we had a rod of length seven the best
thing to do
is to sell it directly for thirty one
the bold lines here are the shortest
path tree
or the longest path tree i guess
and if we had something in length 10 we
should sell it directly if we have
something of length
20 we should sell one thing of length 2
and another thing of left
sorry one thing of length 4 then we
should sell one thing of length
10 of 2 and one of length two we get two
times ten points
and for the 33 case we sell one thing of
length two
one thing of length two and then one
thing of length three
is optimal so you can read lots of
information from this
and if you write down the dp code this
is effectively what it's computing
from left to right
okay let's move on to our second problem
today
which is subset sum
so here we are given
let's say a multi-set
multiset means that i can repeat numbers
so this is just a sequence of numbers
but i'd like to use set notation because
i want to use subsets
because it's subset sum um so this is of
n integers
and we're also given a target sum
and we want to know does any subset
sum to the target sum
this is actually a similar problem to
rod cutting because rod cutting we also
had to split up our number l
into different values that summed to
capital l
so capital t here is playing the role of
capital l but
before we were allowed to cut into any
lengths and so it was easy
in particular l sums to l here
presumably t is not in this multiset
and we need to find a combination of
numbers here that add up exactly to t
sometimes that's possible sometimes it's
not we're only allowed to use each
number once
or as many times as it appears in the
subset
okay so here's an example
say a equals two five
seven eight nine
uh and two examples are t equals 21
and t equals 25
for that same set so can i get 21
out of these well this involves
arithmetic that's hard
i think let's see if i add 7 and 8 i get
15 not quite what i want
cheat look at my answer uh yeah
close i see five seven nine
uh so this is a yes answer to the
question does there exist any subset
because uh 5 7 and 9
sum to exactly 21 and t equals 25 i
don't know a good way to prove to you
that there's no way to write 25 with
these numbers other than
i wrote a program that tried all subsets
and or
you could write a program that runs the
dp
that we're about to give and it will
output no there's no succinct way as far
as we know to
prove to someone that the answer is no
for a given target sum
there is a nice succinct way to prove
the answer is yes i just give you a
subset
we'll talk more about that next lecture
but these are some examples of the
question you might ask and the answer
that we're looking for this is what we
call a decision problem
in its original form we're just
interested in a yes or no answer
uh it's a single bit
of course in the yes case we might
actually want to find the set and we can
do that as usual with parent pointers
just like in the bold lines over here
we'll get to that in a moment
um but this is a little bit different
from the most the problems we've been
seeing with dynamic programming are
optimization problems
and we're trying to minimize or maximize
something and so we always put
a min or a max on the outside in the
relation
here we're going to have to do something
that involves boolean values yes or no
true or false
okay so let's solve it this is actually
also going to be pretty straightforward
um in that we can just use
our standard sets of subproblems
so just like the previous problem we
have
on the one hand a sequence of integers
and on the other hand we're given a
single integer t
and what turns out to be right is to use
prefix
prefixes or suffixes on this
sequence and uh integers less than or
equal to t
let's think about why
so that was sort bot for rod cutting
this is swordbot
for subset sum
again i'll look for a look ahead to
what feature of the solution should i
guess
well i have these n numbers each of them
could be
in my subset or not so i have this
binary choice for each ai
is it in s or not
that's a lot of questions to answer i
can't answer them answer them all at
once but i could just start with
the first one and say well is a 0 an s
yes or no
there's two answers locally brute force
if i do that what happens to my
problem what new sub problems do i run
into what do i want to recurse on well
i've eliminated a zero that will leave a
suffix of the ai's
so suffixes on capital a seem like a
good idea
and what about my target sum well it
depends if i
put a zero in my set s
then the target sum for the remainder is
t minus a0 so t went down
and so i need i need in my sub problems
to represent smaller target sums also
so this is how you figure out what sub
problems you should use don't you
i mean you could just try prefixes on
this
suffixes on this substrings on this and
yes or no do i include
smaller versions of t here but you can
also just think about
try to write a recurrence relation first
see what things you are
naturally recursing on and then
formulate the sub problems that way
so that's what i like to do
so i'm going to have a sub problem for
each suffix
uh so that's x of i
and for each target sum and i use these
capital letters
for the for the actual target sum so
that i can use lowercase letters for
smaller versions of them so this is
going to be
uh does any subset
remember don't first most important
thing is to define
what your sub problems are don't just
say it's the same problem but where i
replace blah blah blah
very it can be very ambiguous and so
uh does any subset s of
the suffix a from i onwards
some to little t
and we're going to have this sub problem
the other important thing is to
say how many sub problems there are and
what your
indices can vary over so i
is going to be between
0 and
n and t is going to be between 0
and big t
okay so number of sub problems is n plus
one times t plus one or theta
n times t cool now i claim i can write a
relation
like i said by so we have this suffix
from a
from i onwards in a and so i'm just
going to
because i'm looking at suffixes i want
to keep with suffixes so i should try to
guess what happens to a of i
because then what will remain is a of i
plus 1 onwards
and a of i can either be in my subset s
or not so there's two choices
so x of i t is going to be
involve two things so there's an
operator here
and then i have a set of two items which
is
uh i could choose to not
put a of i in my subset in that case
i've eliminated a of i and what remains
is uh
a of i plus 1 onwards and i didn't
change my target sum i
i haven't put anything in s so i still
want to achieve the same sum
so this is the case where a
i is not in s
and then the other case is
i put a of i in s
in that case again i've eliminated a of
i and so what remains to figure out is
what happens to
a of i plus 1 onwards but now my target
sum is different because
i put a number in my set and so among
these items
they should sum up to not little t
anymore but now
little t minus what i just added which
is
a i so then if if in this sub problem i
get something that sums to t
minus a i and then i add a i to that set
i will get something that sums to
exactly t
and so that's a valid solution to this
problem
and because we have brute forced
all possibilities there were only two uh
if we
combine these in the suitable way then
we will
have considered all options
now what do we want here so this is
normally i'd write max or min
but this is a decision problem the
output is just yes or no so this is a
yes or no answer this is a yes or no
answer this is a yes or no answer
and so what i want is or
in python this would be called any just
are any of these things true
because if there's any way to construct
a set
that sums to t then the answer to this
is yes
cool so very simple actually just this
is one of the simplest recurrences but
we're solving
what i think is a really impressive
problem right we
we're asking is there any subset they're
exactly two to the n subsets
of a here um and we're in some sense
considering all two to the n of them
but because we split it up into n local
choices
that are binary and do them only one at
a time
sort of this is the local brute force
versus global brute force global brute
force would be trial subsets
sum them see which ones add up but we're
in some sense collapsing a lot of these
choices be
in reusing sub problems that's the whole
point of dynamic programming
we're looking at uh for the the rest of
the
of the sequence from i plus one onwards
i don't really care exactly which subset
you choose i only care what it sums to
and that collapses a lot of different
options into the same
thing i really just want to know is
there any way to do it with exactly this
sum
so i don't have to think i don't i don't
need to keep track
if if i said give me all of the
different subsets that sum to t that
would be exponential time
but because i'm just asking a yes or no
question this choice
only takes constant time and we get to
sum them instead of product then
because we're using memorization that is
the beauty of dynamic programming
and the this time analysis rule
that we only have to sum over sub
problems because we only compute each
sub problem once
so without memoization this would take
exponential time just like fibonacci
with memorization magic i just think
this is
beautiful so even though it's one of our
simpler
dps i think it's an impressive one
okay uh topological order well let's
look at these function calls so here we
have to be a little bit careful
when we call x recursively
we always increment i but sometimes we
don't decrement
t sometimes t doesn't go down so if i
wrote
decreasing t here that would be bad
because
sometimes i call with the same value of
t
and i don't want to get into i want to
ensure that this has already been
computed when i try to compute this
so i is the right thing and we should
say decreasing i
it doesn't actually matter how we order
with respect to
t just any order that is decreasing
i will be good because these function
calls always increase i
okay we need a base case
base cases let's see
the natural given this aspect i think
the natural thing is to have a base case
when
my suffix is empty which is when i
equals n so this is x
of uh
n comma t for any
little t because we don't have a lot of
control of how t
is changing but this is easy so this is
saying if i give you no numbers
what sums can you represent the only sum
i can represent is
0. okay so
if t equals 0
then the answer is yes and
otherwise the answer is no
so that's my base case and that's enough
and we needed this base case because if
we wrote x of n comma t this would try
to call x of n plus 1 which doesn't make
sense
but x of n call in as a natural
suffix which we only allowed i to go up
to n and that's the empty suffix
so this is enough we need the
original problem
uh which is the entire string from zero
onwards
and capital t for little t that's our
target sum
and then the running time
as i said there are n times t sub
problems
theta and the amount of work we spend
for each one that isn't recursion is
constant we just do a couple
subtractions additions
do an or and recursive calls so constant
time
so n times t is the running time
of this algorithm let me
show you an example as a subproblem tag
really helpful to see how these are hard
to draw but they're easy to read
i think they're helpful to show what's
really going on in this dp
this remember every node here
corresponds to a possible subproblem we
could have so we have
the choices for little t on the top the
choices for little i
on the left so the original problem we
care about is i equals 0
t equals 6.
this is the same example that i showed
you before
where we have three or no it's a
different example sorry my new set a
is three four three one
four numbers here my target value is six
this is definitely possible i can add
three and three
this shows that a doesn't have to be
sorted we're not assuming anything about
the order of a
and we're allowed duplicate values and
we see indeed there's a y
here for yes it is possible and how did
i compute that
well i just drew a bunch of arrows
so there's vertical arrows here always
going from each problem to the next one
above it because
we have this dependency x i of t
calls x of i plus 1 comma t
so that's
the calls are going in this direction so
the dependency order is you have to
compute things lower down
before you compute things up here
um and indeed down here is the base case
where we write yes for the first problem
and no for all the others because we
don't have any numbers we can't
represent anything above
zero okay and then we have these blue
lines
i just drew them a different color so
they stand out
hopefully and they correspond to the
numbers here
so our first choice is do we include a
zero which is
three so that's only possible if we're
trying to represent a number
uh that's greater than or equal to three
which reminds me i forgot to write down
in this dp i need to say
this option is only an option
if a i is less than or equal to t
just move my comments here
those are the same so this notation
means
i put this item in this set that we take
an or of
only if this condition holds okay
otherwise i admit it because it's not a
choice
why is that important because i don't
want to call x on a negative value of t
we only are allowed to call x here when
t is between zero and capital t
so that's subtlety but important for a
correct
dp
so then that's why there's no edge from
here for example that goes three to the
left because there's no
vertex there there's no sub problem so
only for
uh little t from three onwards we have
this edge that goes three back
and that's just the same pattern over
and over then our next number is four
and so we have these edges that are go
four to the right
then our next number is three so we
again have edges that go three to the
right
and then our next number is one so we
have these nice diagonal edges that go
one to the right and then what's
happening in here at each stage let's
take an interesting one maybe this
vertex
is we look at each of the incoming
neighbors and we take the or
so the incoming neighbor here has a no
incoming neighbor here has a yes
and so we write a yes here which means
that given just these numbers three and
one
we can represent the number three namely
by taking this edge
of weight three sorry of length
three and then just going straight down
to a base case
that's yes that's representing 0. so in
this case we
this example i didn't draw the parent
pointers here but they're in the notes
this yes is possible not from going this
way but from going this way
so we take the number three then we go
down which means we skip the number
four and then we go left which means we
take the number three and then we go
down which means we skip the number one
okay so we can represent six as three
plus three
cool so subset sum not only can we solve
the decision problem but by following
parent pointers in the yes instances
we can actually find a valid subset
question you added that condition to the
relation
good question um so ins
uh it's it's a generally useful
technique to add
if conditions to the cases to only when
they apply
you can write a lot of dps that way and
that's why i wanted to stress it
you could instead of adding this
condition
allow the case that little t is negative
but you have to think about how negative
would it be
you might say well maybe t between minus
big t
and plus big t is enough i don't think
so it should be
um we're at some value t and we subtract
some ai we don't know how the ai's
compared to big t
probably they're less than or equal to
big t because they're not useful if
they're bigger than big t so you could
first prune the ais to guarantee all the
ais are less than big t
then minus big t to big t would work
otherwise it's like minus the maximum ai
up to big t would be enough i think
yeah does this restrict to only the
positive integers in the input
ah do i i am implicitly assuming here
that all the ai's are positive
uh i think you can solve it with
negative numbers but it's not
uh and maybe we'll do it in recitation
it is not as
it's not a trivial change to this dp
i've definitely thought about it before
yeah so i should have said positive
integers
thank you
cool all right so uh that's subset sum
but we come back to this question of is
this a good algorithm is it polynomial
time
so we have this running time n times t
so a new question
is is n times big t
polynomial
and the answer is no why
because for this problem what is the
input size
how many words of input do i have
well i have these n integers and then i
also have the target sum
so similar to up above our input size is
n plus one
okay but now the labels really matter
before it was l plus one
and and our running time was a function
of l
now our input size is just n plus one
but our running time is a function of
both
n and t
not polynomial
in input size
n plus one you cannot write that n n
times capital t is less than or equal to
n plus 1 to the 27th power
because you just don't know how n and t
relate
maybe t is at most n then we're happy
but maybe it's not maybe t
is 2 to the n why could it be 2 to the n
uh because
what do we know about capital t we
assume
implicitly throughout the course the t
fits in a word
that means it's a w bit number
so that means it's at most two to the w
and you might think well we know about a
relation between w
and n so we know
t is at most 2 to the w
if it's w bits
and we know that our assumption is
always that w is at least log n
that's the word ram trans-dichotomous
assumption
but notice we don't know anything about
an upper bound on w
in order to upper bound t in terms of n
i'd need to say that w
is at most log n then this would be at
most n and we'd be done but that's not
very interesting and generally we allow
w to be arbitrarily large with respect
to log n it just has to be at least log
n
just to be able to index stuff
so but w could be really big
much bigger than log n for example
w equals n is not a crazy idea i mean
if if i have a machine that can
represent n numbers why not represent n
numbers each of which is
n bits long and maybe it takes a little
more time to compute on those
you might want to scale your running
times but it's quite reasonable to think
about n-bit numbers
and then this is like n times 2 to the
n so this would actually be exponential
time
and if w is 2 to the n n times t
is exponential in the problem size
which is n plus 1. and that's just an
example
w could be bigger okay so this is not
what we call a polynomial algorithm or
strongly polynomial algorithm
but it's still pretty good right as long
as we know that capital t
is not ginormous then this is a great
algorithm
so it's and we capture that notion
with a concept called pseudo-polynomial
it's not the best term but it's the
established term it's
like polynomial but not quite and the
definition of this term
so we have the definition of strongly
polynomial time uh now
uh pseudo-polynomial time this i'll
write time here
so you can measure other things
pseudopolynomial
uh is that we're polynomial
uh in the input size
just like before
and the input numbers
input integers
okay so in this problem the input
integers are
capital t and a0 a1
up to a n minus 1. so we want now is a
polynomial or what some people call a
multinomial
where our variables are all of these
integers and we want to be polynomial
in them so we're allowed to take some
constant power of capital t
and some constant number of the ais we
can't just take the product of all of
them that would be
big
so it's a i guess i should say constant
degree polynomial
and indeed this is a you might call it a
quadratic polynomial
in the input size and the and one of the
numbers
so this is this running time is pseudo
poly
but not poly
and so while normally we think of
polynomial time is good exponential time
is bad pseudo-polynomial is what we
normally call
pretty good to be informal
yeah so in particular pseudopolynomial
implies polynomial in the special case
so if the input integers
are all at most polynomial
in the input size
this should sound familiar this is a
constraint we've seen before
this is the condition when radix sort
runs in linear time
ready sort runs in linear time exactly
when
all the input integers are polynomially
bounded
in n which is the size of the array
which is the input size
okay so same same condition is appearing
again so this is sort of a fundamental
setting to think about and let's see
so in particular
other structures we've seen like
counting sort
and direct access arrays are also
pseudopolynomial
any others
fibonacci sorry
rate export yes
technically also rate of sort
are all uh they're not strongly
polynomial
but they are pseudo-polynomial uh here
we thought about this as a dependence on
you which we got rid of using hashing
but if you just use the order u running
time for say build
uh that u is is like are bound on the
input integers and that's only good when
this is polynomial
in general it's pseudo-polynomial same
with counting sort we had
an order u now we improved this in radix
sort to this running time that was
uh n times log base n of u
plus n
if you want to be careful um
so or put a ceiling
uh now this is a running time that's a
little bit better
and this is usually called weekly
polynomial don't want to spend much time
on this
but weekly polynomial is just like
pseudo-polynomial
but instead of being polynomial the
input size and the input integers
your polynomial in the log of the
integers
so this is better and it's almost as
good as polynomial
as strongly polynomial okay we won't
really use this notion the only place
that appears in this class is in rating
sort
but future classes you might care about
so the
the nesting is the best thing you can be
is strongly polynomial
we just call this polynomial in this
class
uh then we have weekly polynomial which
is almost as good but you have this
logarithmic dependence on the numbers
and then the next level is
pseudopolynomial this is
not as good here this really only works
well if the numbers are small
logarithmic dependence is pretty good
because even if they're exponential this
is polynomial
sounds funny but log of an exponential
is polynomial
all right enough about pseudopoly the
last thing
i want to talk about is
reflecting on all of the dynamic
programs we've seen so far
and characterizing them according to the
the big techniques that we used in sort
bot
the first big technique was how do we
define our sub problems
did we take prefixes and suffixes or
substrings
of a sequence did we have multiple
sequences and have to take products of
those spaces
did we have integers and have to take
smaller versions of those integers
sometimes that leads to
pseudo-polynomial algorithms sometimes
not
and sometimes we also had sub problems
that were defined in terms of vertices
this just happened in shortest path
problems because that's the only
setting where we saw dp over graphs so
let me characterize all the dps we've
seen in lecture not the recitation ones
for now
in red
so for example with the bowling problem
with bowling pins we only had to deal
with prefixes
or suffixes because
yeah we were only we could just think
about what happened
for the first couple of pins for example
also for lcs we had to take
two different sequences but then we just
guessed what happened
at the in with the first two items of
each
uh of each sequence and so that only
left us with
suffixes uh with longest increasing
subsequence
again we just guessed whether the first
or maybe
we assumed that the first item was in
the longest increasing subsequence and
then we tried to guess what the next
item was
but that again eliminated everything in
between so we were just left with a
suffix
this leads me to another
characterization
of the kind of dynamic programming
techniques which is for
in addition to these basic sub-problems
we often added constraints and expansion
and lis is an example of what we call
non-expansive constraint where
we just added a constraint to the
problem which was i'd want this first
item to be in my longest increasing
subsequence
but that didn't actually change the
number of sub-problems so it didn't
expand
the number of sub problems this is i
think the only example we saw
with this feature most of the other
times when we added a constraint we also
increased the number of
sub problems which we'll get to
okay also in a certain sense there's
multiple ways to think about this
one floyd warshall is a problem
or we define subproblems based on
prefixes
of the vertices right we had vertices 1
through
n we said is their shortest path using
vertices just
1 to i so that's a prefix of the vertex
set
in a particular order so you can think
of floyd warshall as being
as involving a prefix you can also think
of it as you're given an integer i and
you're only allowed to use vertices less
than or equal to i
and so it's also kind of an integer sub
problem but i will leave it up there
also the two examples we saw today rod
cutting
kind of uh
you could think of it as either a prefix
on the
values or i would prefer to think of it
down here
where we had an integer and we were
considering smaller integers also
and but subset sum definitely had a
suffix
in addition to having an integer
subproblem
so rod cutting you can put down here
because we looked at smaller integers or
up here but subset sum really is up here
and
down here because we both looked at
suffixes and smaller values of t
okay uh fibonacci also fits down here
fibonacci was another case where we had
a number n and we looked at
integers smaller than n ah
good i think i've done these now what
problems involve substrings we saw two
of them
one was the alternating coin game
because we were taking from left or
right and so we had to look at
substrings in between
and the other is parenthesization where
we
had to guess something in the middle and
that left the prefix before it and the
suffix after both of those are typical
ways where you get substring problems
uh okay so
pseudo poly
both of these are pseudo poly
and those those are the ones that we've
seen that are dynamic programs
pseudopoly
and then with vertices it's all the
shortest path uh
problems where we also had a parameter
which was a vertex these are natural
because
in the goal of sort of single short
shortest paths is distance to each
vertex and so naturally we had a sub
problem for each vertex
for dag shortest paths for bellman ford
and for floyd warshall
okay back to subproblem expansion we saw
a couple of examples alternating coin
game and parenthesization
sorry not parenthesization uh yeah
parenthesization sorry
arithmetic parenthesization so here we
consider two different versions of each
subproblem one where i go first and one
where you go first and that was really
handy
though not necessary for
parenthesization it turned out we needed
both min and max in order to solve max
so we really only cared about max so we
doubled the number of sub problems to
make it solvable
for uh piano and guitar fingering
we increase the number of sub problems
by a constant or f
or some f to the f or some uh for
five fingers this is a reasonable
constant um
for some amount of state that we wanted
to keep track of of the past
and one example where we had linear
expansion sort of
is bellman ford so here we were
expanding by how many edges are in the
shortest path
so we really only cared about finding
shortest paths we said oh what about at
most eye
edges so you can think of that as adding
a constraint
and then there's n different variations
of this these sub problems which leads
to expansion
what you could also think of it as just
adding a single constraint which is i
care about the number of edges
and that input is an integer and then
we're looking at the natural subproblem
for integers which is we care about
up to length n minus 1 and now let's
consider all lengths smaller than
n minus 1. okay and finally
the other main feature we had is in the
recurrence relation
and all these shortest path tags how
many incoming edges did we have how many
different
branches did we have to consider and
then
uh combine in some way so we saw a lot
of examples with constant branching
fibonacci where we just was the obvious
two-way branching
bowling where we had a couple of choices
at the beginning
lcs longest common subsequence where we
had a couple choices what to do at the
beginning
alternating coin game similarly
do we take from the left or the right so
just two choices
floyd warshall there's two choices do we
use that vertex or not subset sum
do we include this item in the subset or
not okay
so that was all constant branching in a
lot of the graph problems we got ordered
degree branching which leads to an order
e term in the final running time
namely dag shortest paths and bellman
ford
and then a lot of examples had linear
branching um
in particular longest increasing
subsequence where we didn't know what
the next increasing item was so there
are n possible choices for it
parenthesization where we had to choose
anybody in the middle as the last
operator
and rod cutting that we saw today we
could cut the first rod we cut could be
any length
and then finally once you've considered
all recursed on all these sub problems
you have to combine them
somehow and in a lot of the problems we
actually just
take one the one best choice and that is
our final solution
and in those problems the final solution
ends up being finding some kind of
shortest path in a dag
but there are a few cases where we
actually took multiple solutions and
combined them together to get the
overall solution
and this includes fibonacci which is we
added them
not too interesting floyd warshall we
concatenated two paths
and parenthesization is maybe the most
interesting where we had to take
two parts the prefix and the suffix how
to solve them and then multiply or add
them together
and so these problems are not well
represented by shortest path and a dag
still a dag involved but it's like a
multi-path thing
and then finally at the original problem
often it's just a single sub-problem is
the original problem
and there are a few examples namely dag
shortest paths
and longest increasing subsequence and
bellman ford
and floyd warshall these were the order
that we covered them
so the the three shortest paths and then
longest increasing subsequence where
uh here because we added this condition
we had to try all the possible choices
for this condition
i think uh do we also have one here
today
no okay um
so in fact in retrospect or i mean this
we knew this from the beginning but for
you in retrospect
these four dp lectures were all about
showing you these
main techniques of dynamic programming
from how to set up simple sub problems
to
different types of basic sub problems to
constraining or expanding those sub
problems
and having initially very simple
branching and then getting to
bigger branching and different kinds of
combination we wanted to show you all
these ideas in some order
and if you look back at the sequence
that we covered problems we're kind of
slowly adding these different
main techniques to dp and that's why we
chose the examples we did
there of course many more examples of dp
very powerful technique
but that's the end
you