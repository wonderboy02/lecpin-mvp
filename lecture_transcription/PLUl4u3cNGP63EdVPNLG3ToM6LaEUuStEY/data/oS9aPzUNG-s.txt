okay
so uh it's a pleasure to see all of you
guys i'm justin
i am your third instructor for 6006.
this is my first time with this course
although of course this is material that
we all know and love in a computer
science
department i'll admit i find the
prospect of teaching
sorting to 400 people all at once my
like kind of low-key terrifying but
we're going to give it a shot and
hopefully that will subside as the
lecture goes on today all right
uh so we're going to pick up where we
left off in our last lecture
and continue on with the similar theme
that we're going to see throughout our
algorithms class
here in 6.06 i think jason
and colleagues have done a really great
job of kind of organizing this class
around some interesting themes um so i
thought i'd start with just a tiny bit
of review
of some key uh vocabulary words
incidentally
you know typically i teach the intro
graphics class or geometry course and
last year i got feedback that said i
have serial killer handwriting i'm not
100 sure what that means
but we're gonna use the slides a tiny
bit more than normal just to make sure
you guys can read
and when i'm writing on the board at any
point if you can't
tell what i wrote it's it's definitely
me and not you so just just let me know
uh but in any event uh in 6006 uh
all the way back in our lecture one i
know that was a long time ago we we
introduced two
uh big keywords uh that are closely
related but not precisely the same
hopefully i've gotten this right uh but
but roughly uh
there's a theme here which is that
there's an object called an interface
right which is just sort of like a
program specification right it's just
telling us that
there's a collection of operations that
we want to implement so for example
a set as we're going to see today is
like a big pile of things
and behind the scenes how i choose to
implement it
can affect the run time and and sort of
how efficient my set is
but the actual way that i interact with
it is the same whether i use you know an
unsorted array a sorted array or what
have you
on the other hand what happens behind
the scenes is something called a data
structure
which is a way to actually in some sense
implement an interface right so this is
an object
that on my computer is actually storing
the information and implementing
the set of operations that i've laid out
in my interface
right and so this sort of distinction i
think is is sort of a critical theme
uh in this course because for instance
in the first couple weeks
we're going to talk about many different
ways to implement a set i'm going to see
that there's a bunch of trade-offs right
some of them are really fast for certain
operations and slow for others
uh and and so essentially we have two
different decisions to make when we
choose an algorithm
one is making sure that the interface is
correct for the problem that we're
concerned with
and the other is choosing an appropriate
data structure whose efficiency
and memory usage and so on kind of
aligns
with the priorities that we have for the
application we have in mind
so hopefully this kind of high-level
theme makes sense and really kind of
spiritually i think
that's sort of the main message to get
out of this course in the first couple
weeks even if
you know these o's and thetas and and so
on you know are kind of easy to
lose the force through the trees in any
event
today uh in our lecture we're concerned
with one particular interface which is
called a set
set is exactly what it sounds like it's
a big pile of things
uh and and so a set interface is sort of
like an object that just you can keep
adding things to it and then querying
inside of my set is this object here can
i find it and then maybe i associate
with my
objects in my set different information
so for example
maybe i have a set which represents all
the students in our classroom today
yeah and all of you guys are associated
uh with your student id which i believe
at mit is a number
yeah which has a less than sign which is
convenient so we can sort all of you
guys
and that might be the key that's
associated to every object in the room
and so when i'm searching for students
maybe i enter in the student
number and then i want to ask my set
does this number exist in the set of
students that are in 6006
right and if it does then i can pull
that student back and then associated
with that object is a bunch of other
information that i'm not using to search
so for instance your name your your i
don't know your social security number
credit card number all the stuff that i
need to uh
you know have a more interesting
profession so uh in any event
um let's let's kind of fill in the
details of our our set interface a
little bit more
uh so our set is a container right it
contains
all of the students in this classroom in
some virtual sense at least
uh and so to build up our set of course
we need an operation that takes some
iterable object a
and builds a set out of it right so in
other words i have you know all the
students in this classroom represented
maybe in some other fashion
and i have to insert them all into my
set i can also ask my set for how much
stuff is in it
personally i would call that size but
length is cool too
um and then of course there are a lot of
different ways that we can interact with
our set
right so for instance we could say you
know
is this student taking 6006 so in set
language
one way to understand that is to say
that the key right the
each person in this classroom is
associated with the key
does that key k exist in my set in which
case i'll i'll call this find function
which uh will give me back uh the the
item with key k
or maybe like null or something if it
doesn't exist
uh maybe i can delete an object uh from
my my set or insert it notice that these
are dynamic
operations meaning that they actually
edit what's inside of my set
and then finally there are all kinds of
different sort of operations that i
might want to do to interact with my set
beyond is this thing inside of it right
so for instance
maybe okay so for for the student id
example probably finding like the
minimum id number in a class isn't
a terribly exciting exercise but maybe
i'm trying to find the student who's
been at mit the longest and so that
would be a
kind of reasonable heuristic i actually
have no idea whether mit student ids are
assigned linearly or not but in any
event uh
i could find the smallest key the
largest key and so on
uh in my set and these are all kind of
reasonable operations to query
uh where my object is just a thing that
stores a lot of different entities
inside of
now is this uh description here notice
that i've labeled this as the set
interface this is not a set data
structure
right and the way to remember that is
that i haven't told you how i've
actually
implemented this right i haven't told
you that you know i'm gonna behind the
scenes have an array of information
and and look inside of it and that's how
i'm gonna implement you know find min or
find max with a for loop or whatever
all i'm telling you is that a set is a
thing that implements these operations
and behind the scenes my computer does
what it does
that might sound abstract but it's more
or less what you guys do when you write
code in python right you have
you know addictive i think in python
what we're calling a set is maybe a
dictionary
i'm a matlab coder i'm sorry i'm a
numerical analysis kind of guy
but um essentially you know that one of
the beautiful things about coding
in in these high-level programming
languages is that they take care
of these ugly details and what you're
left with is just the kind of
high-level uh interfacing with this
object that you need at the end of the
day
so of course in today's lecture now that
we've set out our goal
right which is to fill in like if i
wanted to write code for a set
how could i do it now of course our goal
is to give different data structures
that implement these and then understand
them in terms of their
efficiency data storage correctness all
that good stuff
so before we get into all these ugly
details let me pause for a second are
there any
questions about this basic interface
y'all should feel free to stop me
anytime because this is going to be
hella boring if you're not getting the
first slide or two
[Music]
yes
so the question was uh what exactly is
this insert operation doing
so i think working in the analogy of the
students in this classroom is kind of a
reasonable one
so i'm going to build up an object which
is a student right so in this
uh lecture notes i think we've been
consistent i caught one or two typos we
think of x as the object that contains
all of the information
and then associated with that is one
piece which is called the key
that's we're going to use the letter k
right and that's like your student id
that's the thing i'm going to use to
search
right so what the insert operation does
is it takes this whole student object
x which includes your id your name your
phone number all that good stuff
and it starts it into the set with the
understanding that when i search my set
i'm going to be searching by key
right so when i want to find a student i
have to put in my id number
does that make sense cool any other
questions it's great
fabulous okay so now uh let's let's talk
about how to actually implement this
thing and thankfully
we're already equipped with uh at least
a very simple way that we could
implement a set
uh based on what you've already seen in
your previous programming classes or
even in just in the last two lectures
which is one way to understand a set or
to implement it rather
would be to just store a giant array
of objects that are in my set
i suppose uh continuing with the sort of
theme of the last two lectures
this is not a space in memory but rather
a
metaphorical array you know a
theoretical but it doesn't really matter
and
so one way to store my set
would be to just store a bunch of x's in
no particular order
does that make sense so i have a big
piece of memory every piece of memory uh
is associated with a different object in
my set
obviously this is quite easy to build
right i just make a big ray and dump
everything in there
and the question is is this particularly
efficient or useful way
to implement a set right so for instance
let's say that i have
you know i i have a set of all the
students in this classroom
there's like some ridiculous number of
you guys so actually you know asymptotic
efficiency maybe actually
matters a little bit and i want to query
does this student
uh exist in my class you know is eric
domain taking 606
the answer is no i think teaching taking
i don't know
uh but in any event how do i implement
it if my set is unordered
we'll think about it for a second yeah
it's actually an interesting uh
suggestion which is going to anticipate
what's happening later in this lecture
which was to sort the set
and then binary search right but let's
say that actually i only have to do this
once for some reason i build up a whole
set of the people in this classroom
and i just want to know is eric domain
in this class right so then that
algorithm would take n log n time
right because i've got to sort everybody
and then i have to do binary search
which is maybe
login time but i claim that if the only
thing i care about is building up my
entire set
and searching it once there's actually a
faster algorithm this is going to be
needlessly confusing because we're going
to see that this is really
not the right way to implement it in
about 38 seconds
yes yeah just iterate from beginning to
this array
and say is this guy eric no is this guy
eric no is this guy eric
yes and then return him right so in the
worst case
how long will that algorithm take well
in the worst case i have really bad luck
and your instructor is all the way at
the end of the list
right so in this case what is that going
to mean that means that i have to walk
along the entire array
before i find him so that algorithm
takes order and time
and so your colleague's intuition that
somehow this is quite inefficient
is absolutely correct right if i know
that i'm going to have to search my
array many many times for different
people
then probably it makes sense to do a
little bit of work ahead of time like
sorting the list
and then my my query is much more
efficient
but this is all just to say that an
unordered array is a perfectly
reasonable way to implement the set
interface
and then searching that array will take
linear time every single time i search
yup and of course if you go down your
list of all of the different operations
you might want to do
on a set you'll see that they all take
linear time so for instance how do i
build my set
well i have to reserve n slots in memory
right and and at least according to our
kind of model of computation in this
class that takes
order and time right then i got to copy
everything into the set
similarly if i want to insert or delete
what do i have to do
well i have to reserve memory and stick
something inside of there in the worst
case we saw this
amortized argument before if your set is
allowed to kind of grow dynamically
and finally if i wanted to like find the
minimum student id
in my classroom sort of the only
algorithm i can have if my my list of
students isn't sorted
is to what just iterate over every
single student in the class
and if the guy that i'm looking at has a
smaller id than the one that i found
replace it does that make sense to
everybody so basically everything you
can do in a set
you can implement and i think all of you
guys are more than qualified to
implement
as an unordered array it's just going to
be slow yes
yeah that's right so i actually i don't
know in this class
if if you're i guess the set interface
the way that we've described it here is
dynamic we can just keep adding stuff to
it
uh in that case remember this amortized
argument from eric's lecture says that
on
average that will take order end time
what was that oh that's true that's an
even better sorry
uh even if it weren't dynamic um if
i wanted to replace an existing key like
for some reason two students have
the same id this is a terrible analogy
i'm sorry uh but but in any event if i
wanted to replace
uh an object with a new one well what i
have to do i'd have to search for that
object first and then replace it
and that search is gonna take order and
time from our argument before
thank you okay so uh right
in some sense we're done right we've now
implemented this interface life is good
and and of course this is the difference
between you know existence and and
actually uh
caring about the details inside of this
thing right we've shown that one can
implement a set
but it's not a terribly efficient way to
do it by just storing a big like hot
mess
disorganized list of numbers without any
order yeah
so instead of that uh conveniently our
colleague in the front row here has
already suggested a different data
structure
which is to store our set not as just a
disorganized array in any
arbitrary order but rather to keep the
items in our set
organized by key right so in other words
like if i have this array of all of the
students in our classroom
and the very first element in my array
is going to be the student with the
smallest id number
the second is the second smallest id
number all the way to the end of the
array which is a student with the
biggest id number
now does that mean i want to like do
arithmetic on student id numbers
absolutely not
but it's just a way to sort of impose
order on that list so that i can search
it very quickly later
okay so if i want to fill in the set
interface
and i have somehow a sorted array of
students
right so again they're organized by
student id number
then my runtime starts to get a little
more interesting
yeah so now uh insertion deletion still
takes the same amount of time but let's
say that i want to find the student with
the minimum id number right this find
min
function well how could i do it in a
sorted array
keyword is sorted here where's the main
element of an array yes
uh yeah in fact i can give a moderately
faster algorithm which is just look at
the first one
right if i want the minimum element of
an array it
and the array is in sorted order i know
that's the first thing
right so that's order one time to answer
that kind of a question and similarly if
i want the the thing with the biggest id
number
i look all the way at the end now uh in
six double o
what triple o this mit student class
numbers are
super confusing to me uh this in 6 001
604 2 you guys already i think learned
about binary search and
even may have implemented it so what do
we know if my array is sorted
how long does it take for me to search
for any given element
yes login time that's absolutely right
right because i can cut my array in half
you know if my key is bigger or smaller
then i look on the left or the right
and and so this is a much more efficient
uh means of searching a set yeah
uh so in particular you know 6006 this
year has 400 students maybe next year it
has 4 000. you know eventually it's
going to have like billions
right uh then then what's going to
happen well if i use my unordered array
you know and i have a billion students
in this class it's going to happen
well then it's going to take me roughly
a billion computations to find any one
student in this course
whereas log of a billion is a heck of a
lot faster
right on the other hand i've kind of
swept a detail under the rug here
which is how do i actually get a sorted
array to begin with
and what we're going to see in today's
lecture is that that takes more time
than building it if i just have a
disorganized list right building a
disorganized list is the easy thing to
do you probably all do it at home when
you're cleaning house yeah but actually
sorting a list of numbers requires a
little bit more work
and so this is a great example where
there's at least a tiny amount of
trade-off right
where now building my sorted array to
represent my set is going to take a
little more computation we're going to
see it's n log n time
but then once i've done that sort of at
step zero now
a lot of these other operations that i
typically care about at a set like
searching it for a given key
are going to go a lot faster using you
know binary search
okay so so this is our basic uh uh sort
of motivator here
and and so now we've seen the set
interface and two potential data
structures
and our goal for the day is going to be
to kind of fill in the details of that
second one
and since you all have already seen
binary search you've probably also
already seen sorting
but in any event uh today we're going to
focus mostly on the sort of lower left
square here right on just how can i take
a disorganized list of objects
and put it into sorted order so that i
can search for it later
right so in other words our big problem
for a lecture today
is the second thing here right just
sorting
incidentally in the next couple lectures
we're going to see other data sets or
data
structures rather so data structs that
was i used to teach machine learning
class
uh and we'll see that they have
different
sort of efficiency operations that we
can fill in this table so we're not done
yet but this is one step forward
okay so hopefully i have sort of ad
nauseam justified why one might want to
sort things
and indeed there are a couple vocabulary
words that are worth noting uh so one
uh so you remember that your sorting
algorithm is is pretty straightforward
in terms of how you specify it right
so in sorting your input
is an array of
n numbers i suppose actually really
these
we should think of them like keys it's
not going to matter a whole lot
right and our output
i'm always very concerned that if i
write on the board on the back i can
like i
have to cover it up um it's going to be
uh
out it's going to be a sorted
um array right and we'll call this guy b
and we'll call this one uh hey
this classroom is not optimized for
short people
okay uh so there's a lot of variations
on the basic sort of sorting problem and
the different algorithms that are out
there
uh two vocabulary words i'm gonna
highlight really quick one is if your
sort is destructive
what that means is the rather than like
reserving some new memory for my sorted
array b
and then putting a sorted version of a
into b
a destructive algorithm is one that just
overwrites a with a sorted version of a
right so a lot of like certainly the c
plus interface
does this i assume the python one does
too i i always forget this uh
detail in addition to
uh destructive sorts some sorts are in
place
meaning that not only are they
destructive but they also don't use
extra
memory in the process of sorting right
like you could imagine a sorting
algorithm that like
has to preserve a bunch of like scratch
space to do its work and then put it
back into a
right like for instance the world's
dumbest uh
destructive sort might be to call your
non-destructive sort and then copy it
back
into the into a right but that would
require order n space
to do so if my algorithm additionally
has the property that it doesn't reserve
any extra space
at least up to a constant uh then we
call that in place
okay so those are our basic vocabulary
words and they're ways to kind of
understand the differences between
different sorting algorithms
why do they end up using extra oh one
space oh yeah sure like any time
i just make a temporary variable like a
loop counter that
that's going to count toward that order
one but the important thing is that the
number of variables i need doesn't scale
in the length of the list
yep okay so i present to you the
beginning and end of our sorting lecture
which is the world's
simplest uh sorting algorithm i call it
permutation sort
i think it's very easy to prove
correctness for this particular
technique
uh so in permutation sort what can i do
well i know
that if i have an input that's a list of
numbers
there exists a permutation of that list
of numbers that is sorted
kind of by definition right because the
sword is a permutation of your original
list
so what is uh what's a very simple
sorting algorithm well
list every possible permutation
and then just double check which one's
in the right order yeah
so there's sort of two key uh pieces to
this particular technique if we want to
analyze it i don't see a reason to
belabor it too much
but there's sort of one is that we have
to enumerate
the permutations
now if i have a list of n numbers how
many different permutations of n numbers
are there
yes n factorial right
so just by virtue of calling this
permutations function
i know that i incur at least n factorial
time
it might be worse right it might be that
like actually listing permutations takes
a lot of time for some reason like every
permutation itself takes
order and time but at the very least you
know each one of these things looks like
n factorial i want you my my handwriting
is terrible
all right so that's what this omega
thing is doing if i recall properly
uh and then secondarily well we've got
to check
if that particular permutation is sorted
um
how are we going to do that well there's
a very easy way to check if a list is
sorted right i'm gonna do
maybe four i
equals one two and minus one
notice not not a python quota it's gonna
look a little different right
then check you know is b
i less than or equal to
b i uh
plus one right and so if this uh
uh relationship is true for every single
i that's supposed to be a question mark
right this was less than or equal to
with a question mark over it it was my
special notation
right so if i get all the way to the end
of this for loop and this is true
everywhere
then my list is sorted and and life is
good
right so how long does this algorithm
take what's kind of staring you right in
the face right because you have an
algorithm
which is looping from one to n minus one
so
this step incurs order n time i guess
theta event time
because we gotta go all the way into the
list so when i put these things together
permutation sort well remember that
this check if sorted happens for every
single permutation
so at the end of the day our algorithm
takes at least
n factorial times n time
it's a great example of something that's
even worse
than n factorial which somehow in my
head is like the worst possible
algorithm
yeah so do you think that python
implements permutation sword
i certainly hope not yes
right so the question was why is it
omega and not big o which is a fabulous
question in this course
so here's the basic issue i haven't
given you an algorithm for how to
compute
the set of permutations for a list of
numbers i just kind of call some magic
function that i made up
but i know that that algorithm takes at
least n factorial time in some sense or
if nothing else the list of permutations
is n factorial big
because that's all the stuff i have to
compute so i haven't told you how to
solve this problem but i'm convinced
that at least this amount of time
so remember that omega means lower bound
right so when i put it all together
in some sense okay this isn't satisfying
in the sense
that i didn't give you precisely the
runtime of this algorithm but hopefully
i've convinced you that it's super
useless
yeah okay any other questions about that
but great so so if we go back to our
table for the set interface
well in some sense if we implemented it
using this goofy algorithm
then the lower left entry in our table
would be n factorial times n which
wouldn't be so hot
but notice that actually all the rest of
our our operations are not quite
efficient right i can use binary search
i just
obtain the algorithm that i rather
obtain the sorted array
in kind of a funny fashion okay so let's
let's fill in some more interesting
algorithms
as usual i'm talking too much and i'm
nervous about the time but we can we can
skip one of them if we need to
okay so uh i'm gonna have seen uh
selection sort before
i see your hand but we're gonna defer
for a little bit i'm sorry
uh that's fabulous why don't we defer to
the end of lecture and we'll we'll do it
then
okay so so uh the first algorithm that
we'll talk about for sorting which is
somewhat sensible
uh is something called selection sort
selection source exactly what it sounds
like
so uh let's say that we have a list of
oops my laptop and the screen are not
agreed
okay let's say i have a list of numbers
this is a message that jason i think is
sending me in the course notes but i
haven't figured it out uh
but in any event and i want to sort uh
this list of numbers
here's a simple algorithm for how to do
it which is i can find the
biggest number in this whole list and
stick it at the end
yeah so in this case what's the biggest
number in this list everybody
nine good see this is why you go to mit
okay so
uh i'm gonna take that nine i'll find it
and then swap it out with the
the three which is at the end and now
what's my sort of inductive hypothesis
well in some sense it's that everything
to the right of this little red line
that i've drawn here is in sorted order
in this case because there's only one
thing yeah
so now what am i going to do i'm going
to look to the left of the red line find
the next biggest thing
what's that oh come on
there we go yeah yeah wake up okay so uh
right so the next biggest one is the
eight so we're gonna swap it with the
three
put it at the end and so on i think you
guys could all finish this off
i suppose there should be one last line
here where everything is green and we're
happy but
but in some sense we're pretty sure that
an array of one item is in sorted order
uh and so essentially from a high level
what did selection sort do
well it just kept choosing the element
which was the biggest
and swapping it into the back and then
iterating
now in 6006 we're going to write
selection sort in a way that you might
not be familiar with
uh in some sense this is not so hard to
implement with two for loops i think you
guys could all do this at home in fact
you may have already
but in this class because we're
concerned with proving correctness
proving efficiency all that good stuff
we're going to write it in kind of a
funny way which is recursive
now i can't emphasize strongly enough
how little
you guys should implement this at home
this is mostly a theoretical version of
selection sort
rather than one that you would actually
want to write in code because there's
obviously much better way to do it and
you'll see that in your recitation this
week i believe
um but in terms of analysis there's a
nice easy way to write it down
so we're going to sort of take the
selection sort algorithm
and we're going to divide it into two
kind of chunks right one of them
is find me the biggest thing in the
first
k elements of my array i shouldn't use k
because that means key
the first i elements of my array and the
next one
is to swap it into place and then sort
everything to the left right that's sort
of the two pieces here so
let's write that down right
so what did i do well in some sense in
step one here
i found the biggest uh
uh with index
less than or equal to i right so i
started at the end of the list and then
kind of moved backward
right and then uh step two
was to swap that into place notice when
i say swap so for instance when i put
the eight there
well i had to do something with that
three so i just put it where the eight
used to be
and then finally
well am i done no i just put the biggest
thing at the end of my array
so now i have to sort from index one to
i minus one
right because now i know that the last
guy is in sorted order
i see i'll return again just a second so
yes you can't read the handwriting
this is index less than or equal to i
great question
i warned you it's going to be a problem
okay
uh so let's uh let's do step one uh
first
uh so i'm gonna put code on the board uh
and then we're gonna fill in the details
eric is posting on facebook i'm going to
turn that feature off on my watch later
uh okay so uh right the uh
let's let's let's uh let's implement
this this helper function here
this is something we're going to call
prefix max and this is going to find me
the biggest element of array
between index 0 and index i inclusive i
believe
yeah well here's an interesting
observation
really a deep one which is the
the biggest
uh element from zero to i
that's an i sorry uh there's sort of two
cases
right either
it's uh
at index i
meaning like i have the first 10
elements of my array either
it is element number 10 or
what's the other case it ain't yeah
in other words
it has index
less than i this is kind of a tautology
right like either the biggest thing is
at this index or it's not
in which case it has to be to the left
does that make sense
so this gives us a really simple
algorithm for finding the biggest
element in the array between index zero
and index i
which is what i've shown you on the
screen here i'd write it on the board
but i am a slow writer and already low
on time
and so essentially what did i implement
well i
found the biggest element between
index 0 and index i minus 1
right so if i have let's say that i have
an array
i forget the sequence of numbers like 8
3 5
7 9. that'll do it yeah
and so like i give a pointer here which
is i
right then the very first thing that i
do is i compute
the biggest number all the way to the
left of this stuff in this case that is
eight there we go
now i look at the very last element of
my array which is
nine are you killing me today guys okay
and then what do i return well i want
the biggest one between zero
and index i so in this case i return
the nine that makes sense so
you know there's this uh i know jerry
kane at stanford likes to talk about the
uh
what is it the recursive leap of faith
that happens uh another term for this is
induction
right so we want to prove that our uh
our algorithm works
well what do we have to do we have to
show that when i call this function
it gives me the max of my array between
index 0 and index i
for all i right so let's maybe do this
inductive proof a little bit carefully
and then the rest will be we'll be
sloppy about it
right so the base uh case
is i equals zero right well in this case
there's only one element in my array so
it's pretty clear that it's the max
right
okay and now we have to do our inductive
step
right which means that if i call prefix
max with i minus 1 i really do
get the max of my array between 0 and
index i minus 1
and then really i can just look at my
proof
my very deep statement which is that
either
my object is at the end of the array or
it's not
and this is precisely what we need to
justify the inductive step
right essentially there are two cases
either the biggest element of my array
is the last one
or it's not we already by our inductive
hypothesis
have argued that our code can find the
biggest element between
index 0 and index i minus 1.
so as long as we take the max of that
and the very last guy we're in good
shape
okay so this is our our sort of very
informal proof of correctness
okay so now we have to to justify
runtime for this algorithm and that's
like actually not 100 obvious from the
way i've written it here right there's
no for loop
but what do i do well in some sense if
my runtime is a function
s well for one thing
if my array has one element in it
well my runtime you know it might be
seven it might be 23
but at the end of the day it only does
one thing it just returns i
right so in other words it's theta of
one
this isn't terribly insightful but what
else do we know well
when i call my function i call it
recursively on
one smaller index and then i do a
constant amount of work
so i know that s of n is equal to
s of n minus one plus
theta of one right i do a little bit of
extra computation on top of that
anybody guess what this total run time
is going to be
yes yeah order n right
so let's say that we hypothesize that
this takes end time kind of see that
right because like
at step n we call n minus one we call it
minus two
and so on all the way down to one
right if we want to improve this one of
the ways that we uh i think in theory
you guys have learned in the past and
you're gonna
cover in in recitation is a technique
called substitution
what we do is we're going to look at
this relationship and we're going to
hypothesize
that we think s of n maybe
looks something like c n for some
constant c
that doesn't depend on n then all we
have to do is double check that that
relationship is consistent with our
inductive hypothesis
or rather just this recursive function
and if it is then we're in good shape
yeah so in this case well what do i know
i
i've guessed that s of n
is theta of n so oops in particular
uh if i plug into this recursive
relationship here on the left hand side
i'm going to get cn
on the right hand side i'm going to get
c n minus 1
plus theta of 1.
we just have to make sure that this is
like an okay equal sign
so what can i do i can subtract c n from
both sides
maybe put that one on the other side
here i'm gonna get the
c equals big o of one c
is of course a constant so we're in good
shape
my undergrad algorithms professor told
me never to write a victory mark at the
end of a proof
you have to like do a little square but
he's not here okay uh
right so now uh i see you but we're a
little low on time so we'll save it for
the end of lecture
um okay so if we want to implement the
selection sort algorithm
well what do we do well we're going to
think of i
as the index of like that that red line
that i was showing you before
right so everything beyond i is already
sorted
so in selection store the first thing
i'm going to do is find the max element
between 0 and i
and then i'm going to swap it into place
right so this is just a code
version of the the technique we've
already talked about hopefully this
makes sense
right so you find the biggest element
between zero and index i
right that's what we're going to call j
here i swap that
with the one in index i that's step two
and then step three is i still have to
sort everything to the left of index i
and that's that recursive call
okay so if i want to justify the uh
the runtime of this particular technique
well now
let's call that t for time yeah
well what do i do well for one i call
selection sort with index i minus one
right so that incurs time that looks
like this
but i also call that prefix max function
and how much time does that take that
takes order end time yeah
so at the end of the day
i have some relationship that looks like
this does that make sense
so by the way notice that this order n
kind of swallowed up the like order one
computations that i had to do
like to swap and so on okay
so remember uh there's this nice uh
relationship which you probably learned
in your combinatorics class
which is that one plus two plus dot dot
plus n
okay i can never remember exactly the
formula but i'm pretty sure that it
looks like n squared yeah
so based on that and and taking a look
at this uh recursive thing right which
is essentially doing exactly that right
n plus n minus 1 plus n minus 2 and so
on
i might hypothesize that this thing is
really
order n squared so if i'm going to do
that then again if i want to use the
same technique for proof
i have to plug this relationship in and
then double check that it's consistent
right so uh maybe i hypothesize that t
of n
equals c n squared in which case i plug
it in here
i have c n squared equals with a
question mark over it
c n minus 1 squared plus
big o or even theta of n here
so if i expand the square notice i'm
going to get c times n squared
plus a bunch of linear stuff right so
this is really
c n squared uh
i should be careful with it uh minus 2
c n plus c plus
theta of n yeah
notice that there's a c n squared on
both sides of this equation
they go away and what i'm left with is a
nice consistent
uh formula right that theta of n
equals 2 c n plus
oops minus c and indeed this is an order
n expression
so there's order in the universe life is
good yeah this is the substitution
method and
again i think you'll cover it more in
your recitation so what have we done we
have derived the selection sort
we've checked that it runs an n squared
time uh
and uh uh by sort of this nice inductive
strategy we know that it's correct so
life is pretty good
unfortunately i promise for you guys on
the slides that sorting really takes n
log
n time and this is an order n squared
algorithm so we're not quite done yet
i'm way over time so we're going to skip
a different algorithm which is called
insertion sort also runs an end time
uh okay uh where essentially insertion
sort kind of runs in the reverse order
right i'm going to sort everything to
the left
and then insert a new object whereas in
selection sort i'm going to choose the
biggest object and then sort everything
to the left
but i'll let you guys piece through that
at home it's essentially the same
argument
and instead we should jump to an
algorithm that actually uh matters
which is uh something called merge story
that means i've encountered merge sort
before
fabulous good so then i'm done uh no
okay so so let's say that i have
a list now i'm sending a message back to
jason i made this one up last night
uh so i have seven one five six two four
nine three
this is not in sorted order but i can
make a very deep observation which is
that every number by itself is in sorted
order if i think of it as an array of
length one
yeah this is really deep like a deep
learning deep
okay so now what can i do well i could
take every pair of numbers
draw a little red box well now they're
not in sorted order anymore inside of
the red boxes so i'm going to sort
inside of every box in this case not too
exciting because it's just pairs
and now they're in sorted order because
i said they were now i'm going to keep
doubling the size of my boxes so now
let's say i have box of length four
what do i know about the left and right
hand sides of the dotted lines here
on the two sides of the dotted lines the
array is in sorted order right there's a
one and then a seven
right those are in sorted order five and
a six that's because in the previous
step i sorted every pair
so when i merge these two sides together
i have an additional useful piece of
information right
namely that the two sides of the dotted
line are already in sorted order that's
going to be our basic sort of inductive
step here
yeah so in this case i merge the two
sides i get
one five six seven and two three four
nine then finally i put these two things
together
and i have to sort these two uh uh i
have to merge these two sorted lists
but they're in sorted order yeah and
that's going to give me a big advantage
right because uh oops i lost my truck
i suppose i've got space on this board
here
oh no uh right so if i want to
merge one five six seven
and two three four nine
there's like a nice clever technique
that we can do uh that's going to take
just linear time
jason tells me it's the two-finger
algorithm i think that's kind of a cute
analogy here
so here are my two fingers they're going
to point at the end of the list
and i'm going to construct the merged
array backwards
so how many elements are in my merged
array if i'm merging two things of
length four
i don't ask you guys hard questions it's
eight
yeah two four plus four eight yeah okay
so what do i know i know that my merge
array
ah five six seven has eight
elements and now i'm gonna have two
fingers at the end of my array
which one should i put at the end of the
merged guy
the seven or the nine
the nine right thank you right
so now i can move my lower finger to the
left
right because i've already added that
notice that i never need to look to the
left of where my finger is because
they're already in sorted order
right now what should i add the four the
seven
the seven and so on dot dot
dot yeah so that's going to be the basic
idea of the merge sort i'm going to take
two sorted lists
i'm going to make a new sorted list
which is twice as long by using two
fingers
moving uh from the end backward okay so
that's the basic intuition here
indeed there's our sorted list stressing
me out that there's no eight but
i needed a power of two um
so i think the merge sort we're gonna
present in kind of a backward way from
the previous one where i'm gonna give
you the high level algorithm
and then actually the headache is that
merging step which i have four minutes
for and i apologize for
so what does the merge sort do well it
computes an index c
which is the middle of my array and it's
going to make a recursive call which
says sort the left right which is
everything between index a and index c
and then sort everything on the right
which is everything from index c
to index b i know this is confusing
because usually letters appear in order
but c if you think of as standing for
center then it kind of makes sense like
here's my array
i'm going to like choose an index right
in the middle i've done myself a
disservice by not using a power of
two but that's okay i'm gonna say
sort everything to the left of the
dotted line first sort everything to the
right of the dotted line second
now i have two sorted lists on the two
sides of the dotted line
and then i'm gonna use my two fingers to
put them together
okay so that's what this is implementing
here see there's two recursive calls
sort from a to c and then sort from c to
b oops i didn't actually label this
so this is a c b
and then i gotta call merge
okay now our implementation of merge
well we can also do this in a recursive
fashion but i
personally find this a little
complicated i'm going to admit but
here's the basic
idea here which i'm now rushing
so i'm going to think of my upper finger
as finger i
in my lower finger as finger jack does
that make sense
okay so i have two sorted lists
so maybe like that i don't know one
three five seven and then i have a
second sorted list
here which is maybe two four
72 as one does
then i'm going to have one pointer like
this which is
i and a pointer down here
which is j right and my goal is to
construct
an array a
with a bunch of elements in it and the
way that i'm going to do it
is i'm going to use exactly the same
kind of recursive argument right that i
can either
have the biggest element of my array be
the last element of the first guy
or be the last element of the second one
yeah so here's our going to be our
recursive call
and in addition to that for convenience
we'll have a third index
which is b which is pointing to the sort
of thing inside of my my assorted array
that i'm currently processing yeah just
gonna start it a
go to b yeah instantly i see a lot of
people taking photos of the slides uh
these are just copy pasted from the
course notes
um okay so in this case what should i
put in b
for my two arrays i have one three five
seven two four six seventy two
seventy two yeah
great so now what am i going to do i'm
just going to call the merge function
but i'm going to decrement b
because now i'm happy with that last
element in addition to that
i'm going to decrement j because i
already used it up
and so that's our recursive call here
right it's saying
if j is launching equal to zero so in
other words i have an element to use
in in one of the list or the other and
uh that maybe the left one is bigger
than the right one
right that's our first case that does
not apply in this example here
well then i should make the last element
of a from the first list and then
recurse
um with one fewer element i
and similarly the reverse case for j
okay so if we do our run time in two
minutes or less bear with me guys
uh well what is this merge function
going to do
well in some sense there's two branches
right there's an if statement with two
pieces
but both of those pieces call merge with
one fewer
uh piece in it right so in some sense we
have
s of n equals s n minus 1
plus theta of 1 which we already know
from our previous proof means that s of
n is equal to theta of n
so in other words it takes linear time
to merge
it kind of makes sense intuitively right
because essentially you're touching
every one of these things once
with your two fingers
and now our probably the hardest part of
the lecture which i left zero time for
is deriving the run time for the actual
merge sort algorithm
and what does that look like well that
one's a little bit trickier
right because of course i call the merge
sort algorithm
twice each time on a list that's half
the size
in this class we're going to assume that
our list is always the power of two in
its length
otherwise this analysis is a itty-bitty
bit more of a headache so first of all
how long does it take to sort an array
of length one
i legit i'm not going to ask hard
questions everybody
yeah just just like one right because
like there's nothing to do my
array of length one has has one element
and it's sorted it's also
you know the biggest element and the
smallest element
okay and now what does our algorithm do
well it makes two recursive calls on
lists that are half the length
yeah and then it calls that merge
function and we know
that the merge function takes theta of n
time
that makes sense so
uh one thing we might do because we have
some intuition from your
your 6042 course is that we think
that this thing is order
n log n right because it makes that two
recursive calls and then it puts them
together
and let's double check that that's true
really quick using the substitution
method
so in particular on the left hand side
here maybe i have c
and log n now i have two
c well i have to put in n
over 2 log n over 2
plus theta of n and i want to double
check that this expression is consistent
i've got about a foot to do it in okay
so remember uh let's see if we use our
favorite
uh identities from from high school
class that you probably forgot
remember that log of two things divided
by each other is the difference of the
logs
right so this is really two uh okay two
divided by two
is one so this is uh c
times n times log
n minus log of two
yeah plus theta of n
i'm already out of time but notice that
there's a c
n log n on the right hand side there's a
c
n log n on the left-hand side so those
two things
go away and what am i going to be left
with
i'm going to be left with theta of n
equals c
n log of 2.
notice that c and log 2 are both
constants we have a theta of n on the
left-hand side so there's order on the
universe and and we've derived our
runtime
so i know i rushed a little bit through
merge sort i'm sure that eric and and
jason can can review this a little bit
next time
uh but with that we'll see you uh what
thursday and friday and it's been a
pleasure to talk to you all